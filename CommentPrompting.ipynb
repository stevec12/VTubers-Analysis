{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNF8hcB35SyOGuAXNE82xlk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stevec12/VTubers-Analysis/blob/main/CommentPrompting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comment Prompting\n",
        "This Jupyter notebook looks at training a basic transformer to provide responses to prompts based on how a YoutTuber's comments would likely reply.\n",
        "\n",
        "The YouTuber chosen is for the demo is [Ceres Fauna](!https://www.youtube.com/channel/UCO_aKKYxn4tvrqPjcTzZ6EQ), an English streamer with predominantly English comments.\n",
        "\n",
        "The channel ID is `UCO_aKKYxn4tvrqPjcTzZ6EQ`."
      ],
      "metadata": {
        "id": "R9P3PkBKBAqK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Extraction\n",
        "The `YouTube Data API v3` can be used for this task, and an account-linked API-key can be obtained using your personal Google (Developer) Account."
      ],
      "metadata": {
        "id": "nKHKEv3UCDd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import googleapiclient.discovery\n",
        "import googleapiclient.errors\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "!pip install xlsxwriter\n",
        "import xlsxwriter"
      ],
      "metadata": {
        "id": "zU9QbdDpRqeR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "255a5f3d-73b3-47f2-beea-61d5ba53128d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.1.9-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.1.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input API Key: \")\n",
        "api_key = input()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "633vu2o7P3Rs",
        "outputId": "ec005340-c894-4295-8b87-ac251db33fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input API Key: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VNtmD6yA9KH"
      },
      "outputs": [],
      "source": [
        "# Input target channel, example is @CeresFauna\n",
        "channelID = 'UCO_aKKYxn4tvrqPjcTzZ6EQ'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_service_name = \"youtube\"\n",
        "api_version = \"v3\"\n",
        "youtube = googleapiclient.discovery.build(api_service_name, api_version, developerKey=api_key)"
      ],
      "metadata": {
        "id": "bnUk47X1WPjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_uploadedID(channelID):\n",
        "  request = youtube.channels().list(\n",
        "      part=\"contentDetails\",\n",
        "      id=channelID\n",
        "    )\n",
        "  response = request.execute()\n",
        "\n",
        "  return response['items'][0]['contentDetails']['relatedPlaylists']['uploads']"
      ],
      "metadata": {
        "id": "jkoA1_GiWU09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploadedID=find_uploadedID(channelID)"
      ],
      "metadata": {
        "id": "7LkCawW_WcQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_uploaded(uploadedID):\n",
        "  videoIDs = []\n",
        "  request = youtube.playlistItems().list(\n",
        "        part=\"contentDetails\",\n",
        "        playlistId = uploadedID,\n",
        "        maxResults = 50\n",
        "  )\n",
        "  response = request.execute()\n",
        "  for item in response['items']:\n",
        "    videoIDs.append(item['contentDetails']['videoId'])\n",
        "  while('nextPageToken' in response):\n",
        "    request=youtube.playlistItems().list(\n",
        "        part='contentDetails',\n",
        "        playlistId=uploadedID,\n",
        "        pageToken=response['nextPageToken'],\n",
        "        maxResults=50)\n",
        "    response = request.execute()\n",
        "    for item in response['items']:\n",
        "      videoIDs.append(item['contentDetails']['videoId'])\n",
        "\n",
        "  return videoIDs"
      ],
      "metadata": {
        "id": "oefayJeWXusJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded=find_uploaded(uploadedID)"
      ],
      "metadata": {
        "id": "pwn7iZ7MXw_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_comments(videoID : str) -> pd.DataFrame:\n",
        "  '''\n",
        "  Given a videoID, return a pandas DataFrame with video info\n",
        "  '''\n",
        "  column_names = ['videoID','isTopLevel','topLevelID','commentID','authorDisplayName',\n",
        "                  'likeCount','publishedAt','totalReplyCount','textOriginal']\n",
        "\n",
        "  row_list = [] # Used to create list of dict of rows before conversion to dataframe, faster\n",
        "  pageToken=''\n",
        "  while(True):\n",
        "    request=youtube.commentThreads().list(\n",
        "        part=\"id,snippet,replies\",\n",
        "        videoId=videoID,\n",
        "        pageToken=pageToken,\n",
        "        maxResults=100\n",
        "    )\n",
        "    try:\n",
        "      response=request.execute()\n",
        "    except googleapiclient.errors.HttpError:\n",
        "      break\n",
        "\n",
        "    for commentThread in response['items']:\n",
        "      # write top level comment\n",
        "      topLevelID=commentThread['snippet']['topLevelComment']['id']\n",
        "      commentID=topLevelID\n",
        "      authorDisplayName=commentThread['snippet']['topLevelComment']['snippet']['authorDisplayName']\n",
        "      likeCount=commentThread['snippet']['topLevelComment']['snippet']['likeCount']\n",
        "      publishedAt=commentThread['snippet']['topLevelComment']['snippet']['publishedAt']\n",
        "      totalReplyCount=commentThread['snippet']['totalReplyCount']\n",
        "      textOriginal=commentThread['snippet']['topLevelComment']['snippet']['textOriginal']\n",
        "\n",
        "      row_list.append({'videoID':videoID,'isTopLevel':True,'topLevelID':topLevelID,\n",
        "                      'commentID':commentID,'authorDisplayName':authorDisplayName,\n",
        "                      'likeCount':likeCount,'publishedAt':publishedAt,\n",
        "                      'totalReplyCount':totalReplyCount,'textOriginal':textOriginal})\n",
        "\n",
        "      # If any replies, write them as well\n",
        "      if 'replies' in commentThread:\n",
        "        for reply in commentThread['replies']['comments']:\n",
        "          commentID=reply['id']\n",
        "          authorDisplayName=reply['snippet']['authorDisplayName']\n",
        "          likeCount=reply['snippet']['likeCount']\n",
        "          publishedAt=reply['snippet']['publishedAt']\n",
        "          textOriginal=reply['snippet']['textOriginal']\n",
        "\n",
        "          row_list.append({'videoID':videoID,'isTopLevel':False,'topLevelID':topLevelID,\n",
        "                           'commentID':commentID,'authorDisplayName':authorDisplayName,\n",
        "                           'likeCount':likeCount,'publishedAt':publishedAt,\n",
        "                           'totalReplyCount':totalReplyCount,'textOriginal':textOriginal})\n",
        "\n",
        "    if 'nextPageToken' not in response:\n",
        "      break\n",
        "    else:\n",
        "      pageToken=response['nextPageToken']\n",
        "\n",
        "  return pd.DataFrame(row_list, columns=column_names)\n"
      ],
      "metadata": {
        "id": "msEQBZdbYkRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def uploaded_comments_to_excel(file_name, uploaded = uploaded):\n",
        "  '''\n",
        "  Writes all comments in the Uploaded playlist to an excel file, as a single\n",
        "  worksheet.\n",
        "  '''\n",
        "  column_names = ['videoID','isTopLevel','topLevelID','commentID','authorDisplayName',\n",
        "                  'likeCount','publishedAt','totalReplyCount','textOriginal']\n",
        "  comment_df = get_video_comments(uploaded[0])\n",
        "\n",
        "  for videoID in uploaded[1:]:\n",
        "    comment_df = pd.concat([comment_df, get_video_comments(videoID)])\n",
        "\n",
        "  comment_df.to_excel(file_name, engine='xlsxwriter', index=False)\n"
      ],
      "metadata": {
        "id": "ZSJKXRcXsCWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded_comments_to_excel('ceres_fauna_comments_10_27_2023.xlsx')"
      ],
      "metadata": {
        "id": "ccL9tBPR1sE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the Data\n",
        "Preparing the data using TensorFlow preprocessing layers.\n",
        "\n",
        "Here, we use the `ceres_fauna_comments_10_27_2023.xlsx` excel file generated earlier."
      ],
      "metadata": {
        "id": "I6_e9cNGbCCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "!pip install tensorflow_text\n",
        "import tensorflow_text as text\n",
        "from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC6gkYsRbBvh",
        "outputId": "8cf1747e-7639-4f07-fd72-5572f5680ede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (0.15.0)\n",
            "Requirement already satisfied: tensorflow<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (2.14.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (1.59.0)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.15,>=2.14.0->tensorflow_text) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (3.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (3.2.2)\n",
            "Installing collected packages: tensorflow_text\n",
            "Successfully installed tensorflow_text-2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data into a pandas DataFrame\n",
        "comments_df = pd.read_excel('ceres_fauna_comments_10_27_2023.xlsx')"
      ],
      "metadata": {
        "id": "MKNeeBITas9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We filter out comments that are not at least two seperate words\n",
        "multiple_word_indices = np.char.find(comments_df['textOriginal'].to_numpy(dtype='str'), \" \") > -1\n",
        "multiple_word_series = comments_df.copy().loc[multiple_word_indices]['textOriginal']\n",
        "\n",
        "comments_tensor = tf.convert_to_tensor(multiple_word_series.to_numpy(dtype='str'), dtype='string')"
      ],
      "metadata": {
        "id": "qtITGgm8QC-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split the data into train, validation, and test splits.\n",
        "\n",
        "For reasonable training times, we use a 50/10/40 split."
      ],
      "metadata": {
        "id": "gc35nzFoh27I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comment_ds = tf.data.Dataset.from_tensor_slices(comments_tensor).shuffle(1000, seed=12)\n",
        "\n",
        "train_split = int(np.floor(0.5*len(comment_ds)))\n",
        "val_split = int(np.floor(0.1*len(comment_ds)))\n",
        "test_split = int(len(comment_ds) - train_split - val_split)\n",
        "\n",
        "train_ds = comment_ds.take(train_split)\n",
        "val_ds = comment_ds.skip(train_split).take(val_split)\n",
        "test_ds = comment_ds.skip(train_split + val_split).take(test_split)"
      ],
      "metadata": {
        "id": "hQZ9PIJRcDRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate vocabulary using [subword tokenizers](https://www.tensorflow.org/text/guide/subwords_tokenizer) tutorial."
      ],
      "metadata": {
        "id": "JvT9hq5SfjSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tokenizer_params=dict(lower_case=True)\n",
        "reserved_tokens=[\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n",
        "\n",
        "bert_vocab_args = dict(\n",
        "    # The target vocabulary size\n",
        "    vocab_size = 8000,\n",
        "    # Reserved tokens that must be included in the vocabulary\n",
        "    reserved_tokens=reserved_tokens,\n",
        "    # Arguments for `text.BertTokenizer`\n",
        "    bert_tokenizer_params=bert_tokenizer_params,\n",
        "    # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n",
        "    learn_params={},\n",
        ")"
      ],
      "metadata": {
        "id": "r6VcV382kgH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_file = 'vocab.txt'"
      ],
      "metadata": {
        "id": "UHHDzYZpyWs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# vocab = bert_vocab.bert_vocab_from_dataset(\n",
        "    train_ds.batch(1000).prefetch(2),\n",
        "    **bert_vocab_args\n",
        ")\n",
        "\n",
        "# Save vocab to file\n",
        "\n",
        "with open(vocab_file, 'w') as f:\n",
        "  for token in vocab:\n",
        "    print(token, file=f)"
      ],
      "metadata": {
        "id": "lMFV_8B6gBSZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "518882df-9c10-45d4-d9db-2757d611f571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 26s, sys: 419 ms, total: 2min 27s\n",
            "Wall time: 2min 28s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 0\n",
        "with open(vocab_file, \"rb\") as f:\n",
        "    vocab_size = sum(1 for _ in f)"
      ],
      "metadata": {
        "id": "D7B3Qx6-xshl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize, trim (to `MAX_TOKENS`), and pad the inputs, as well as form into (input, label) Datasets where the label is the input right-shifted by one token.\n",
        "\n",
        "Then batch (batch size = `BATCH_SIZE`) and prefetch data."
      ],
      "metadata": {
        "id": "QshfKIgWC-k9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = text.BertTokenizer(vocab_file, **bert_tokenizer_params)"
      ],
      "metadata": {
        "id": "lWW4j7rpud-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_TOKENS = 128\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "Y8sIifsFVN2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "START = tf.argmax(tf.constant(reserved_tokens) == \"[START]\")\n",
        "END = tf.argmax(tf.constant(reserved_tokens) == \"[END]\")\n",
        "\n",
        "def add_start_end(ragged):\n",
        "  count = ragged.bounding_shape()[0]\n",
        "  starts = tf.fill([count,1,1], START)\n",
        "  ends = tf.fill([count,1,1], END)\n",
        "\n",
        "  return tf.concat([starts, ragged, ends], axis=1)"
      ],
      "metadata": {
        "id": "DmoG18ibUxC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_batch(input_batch : tf.Tensor):\n",
        "  '''\n",
        "  Take a tensor outputting only (input) and tensorflow.text.Tokenizer to form\n",
        "  a Dataset outputting (input, feature) where the feature is one token\n",
        "  right-shifted from the input.\n",
        "  Additionally, output Dataset is trimmed and 0-padded dense tensor.\n",
        "  '''\n",
        "  # Tokenize\n",
        "\n",
        "  in_tokenized = tokenizer.tokenize(input_batch)[:,:MAX_TOKENS-2,:]\n",
        "  in_tokenized = add_start_end(in_tokenized) # Add [START],[END] to vectors\n",
        "\n",
        "  te_tokenized = tokenizer.tokenize(input_batch)[:,:MAX_TOKENS-1,:]\n",
        "  te_tokenized = add_start_end(te_tokenized)\n",
        "\n",
        "  la_tokenized = tokenizer.tokenize(input_batch)[:,:MAX_TOKENS-1,:]\n",
        "  la_tokenized = add_start_end(la_tokenized)\n",
        "\n",
        "  # 0-Pad and convert to dense tensor\n",
        "  in_tokenized = tf.squeeze(in_tokenized.to_tensor(shape=(BATCH_SIZE,MAX_TOKENS,1)))\n",
        "  te_tokenized = tf.squeeze(te_tokenized[:,:-1,:].to_tensor(shape=(BATCH_SIZE,MAX_TOKENS,1)))\n",
        "  la_tokenized = tf.squeeze(la_tokenized[:,1:,:].to_tensor(shape=(BATCH_SIZE,MAX_TOKENS,1)))\n",
        "  # form Dataset\n",
        "  output_batch = ((in_tokenized,te_tokenized),la_tokenized)\n",
        "\n",
        "  return output_batch"
      ],
      "metadata": {
        "id": "pxt3NRlYz6A5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_batches(ds):\n",
        "  return (\n",
        "      ds\n",
        "      .batch(BATCH_SIZE)\n",
        "      .map(prepare_batch, tf.data.AUTOTUNE)\n",
        "      .prefetch(buffer_size=tf.data.AUTOTUNE))"
      ],
      "metadata": {
        "id": "e4alFxA31AbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_batches = make_batches(train_ds)\n",
        "val_batches = make_batches(val_ds)"
      ],
      "metadata": {
        "id": "9zj0rkrc3CHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a singular batch as an example."
      ],
      "metadata": {
        "id": "JY7eV-WH5Jjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for (input,teacher), label in train_batches.take(1):\n",
        "  break"
      ],
      "metadata": {
        "id": "--IoHCaM4CfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input[0])\n",
        "print(teacher[0])\n",
        "print(label[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LteMAF345NfI",
        "outputId": "b8585138-cfd1-47aa-b1ea-d79e9020ac2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[   2 1006 2550  205 1157   17 1461 1021 1001 1007 1076 1538  988 1564\n",
            "    3    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0], shape=(128,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[   2 1006 2550  205 1157   17 1461 1021 1001 1007 1076 1538  988 1564\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0], shape=(128,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[1006 2550  205 1157   17 1461 1021 1001 1007 1076 1538  988 1564    3\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0], shape=(128,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert tokens to vectors with a `tf.keras.layers.Embedding` layer and add positional encoding."
      ],
      "metadata": {
        "id": "hYz1JD16eWZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(length, depth):\n",
        "  depth = depth/2\n",
        "\n",
        "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
        "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
        "\n",
        "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
        "  angle_rads = positions * angle_rates      # (pos, depth)\n",
        "\n",
        "  pos_encoding = np.concatenate(\n",
        "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
        "      axis=-1)\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "wJyTvASxeVO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "  def __init__(self, vocab_size, d_model):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
        "    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
        "\n",
        "  def compute_mask(self, *args, **kwargs):\n",
        "    return self.embedding.compute_mask(*args, **kwargs)\n",
        "\n",
        "  def call(self, x):\n",
        "    length = tf.shape(x)[1]\n",
        "    x = self.embedding(x)\n",
        "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
        "    return x"
      ],
      "metadata": {
        "id": "octsiexdfjQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed = PositionalEmbedding(vocab_size=vocab_size, d_model=512)\n",
        "te_emb = embed(teacher)\n",
        "te_emb._keras_mask;\n",
        "in_emb = embed(input)\n",
        "in_emb._keras_mask;"
      ],
      "metadata": {
        "id": "BufCEm_9gKYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()"
      ],
      "metadata": {
        "id": "8Qk7KH4D5XQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossAttention(BaseAttention):\n",
        "  '''def __init__(self, **kwargs):\n",
        "    print('Initializing CrossAttention')\n",
        "    super().__init__(self, **kwargs)'''\n",
        "\n",
        "  def call(self, x, context):\n",
        "    attn_output, attn_scores = self.mha(\n",
        "        query = x,\n",
        "        key = context,\n",
        "        value = context,\n",
        "        return_attention_scores = True\n",
        "    )\n",
        "    # Cache the attention scores for plotting later.\n",
        "    self.last_attn_scores = attn_scores\n",
        "\n",
        "    x = self.add([x,attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "7aSUK3LaafK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_ca = CrossAttention(num_heads=2, key_dim=512)\n",
        "print(in_emb.shape)\n",
        "print(sample_ca(in_emb, te_emb).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZP163reubafg",
        "outputId": "07f9ff07-52cf-444d-d3a4-3fab8454f0ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 128, 512)\n",
            "(64, 128, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GlobalSelfAttention(BaseAttention):\n",
        "  def __call__(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query = x,\n",
        "        key = x,\n",
        "        value = x\n",
        "    )\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "WAJfmyXYFd1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_gsa = GlobalSelfAttention(num_heads=2, key_dim=512)\n",
        "print(in_emb.shape)\n",
        "print(sample_gsa(in_emb).shape)"
      ],
      "metadata": {
        "id": "tArDk3HGCEEr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2691d1c1-5695-4072-b847-1cad04a7ade4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 128, 512)\n",
            "(64, 128, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalSelfAttention(BaseAttention):\n",
        "  def __call__(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query = x,\n",
        "        key = x,\n",
        "        value = x,\n",
        "        use_causal_mask = True\n",
        "    )\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "09Pw5iY0CT5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_csa = CausalSelfAttention(num_heads=2, key_dim=512)\n",
        "print(te_emb.shape)\n",
        "print(sample_csa(te_emb).shape)"
      ],
      "metadata": {
        "id": "n0QspLB2Enrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0490e392-c863-4d1a-f4cc-7ec42a7e0c8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 128, 512)\n",
            "(64, 128, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.seq = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(dff, activation='relu'),\n",
        "        tf.keras.layers.Dense(d_model),\n",
        "        tf.keras.layers.Dropout(dropout_rate)\n",
        "    ])\n",
        "    self.add = tf.keras.layers.Add()\n",
        "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.add([x,self.seq(x)])\n",
        "    x = self.layer_norm(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "ubYe9mNEFUGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_ffn = FeedForward(512,2048)\n",
        "\n",
        "print(te_emb.shape)\n",
        "print(sample_ffn(te_emb).shape)"
      ],
      "metadata": {
        "id": "eDIjRizeM5x-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8741433a-ea55-4d8c-bfc0-d39307098135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 128, 512)\n",
            "(64, 128, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,*,d_model,num_heads,dff,dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.self_attention = GlobalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate\n",
        "    )\n",
        "    self.ffn = FeedForward(d_model,dff)\n",
        "\n",
        "  def call(self,x):\n",
        "    x = self.self_attention(x)\n",
        "    x = self.ffn(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "qn8SHOyGNFgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_encoder_layer = EncoderLayer(d_model=512, num_heads=8,dff=2048)\n",
        "print(in_emb.shape)\n",
        "print(sample_encoder_layer(in_emb).shape)"
      ],
      "metadata": {
        "id": "avMB0tQCPgT7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7285bd71-2e56-44ce-b0b7-f4f9f93ed81d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 128, 512)\n",
            "(64, 128, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(\n",
        "        vocab_size = vocab_size, d_model = d_model\n",
        "    )\n",
        "\n",
        "    self.enc_layers = [\n",
        "        EncoderLayer(d_model=d_model,\n",
        "                     num_heads=num_heads,\n",
        "                     dff=dff,\n",
        "                     dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)\n",
        "    ]\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self,x):\n",
        "    # `x` is token-IDs shape: (batch_size, seq_len)\n",
        "    x = self.pos_embedding(x) # Shape '(batch_size, seq_len, d_model)'.\n",
        "\n",
        "    # Add dropout\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x)\n",
        "\n",
        "    return x # Shape `(batch_size, seq_length, d_model)`"
      ],
      "metadata": {
        "id": "mjYtpLjSQOvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test encoder\n",
        "sample_encoder = Encoder(num_layers=4, d_model=512, num_heads=8, dff=2048, vocab_size=vocab_size)\n",
        "sample_encoder_output = sample_encoder(input,training=False)\n",
        "\n",
        "print(in_emb.shape)\n",
        "print(sample_encoder_output.shape) # Shape `(batch_size, input_seq_len, d_model)`"
      ],
      "metadata": {
        "id": "_VPjyUQvU2Ta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e064ad49-f42d-4411-aefc-c2c8148c8111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 128, 512)\n",
            "(64, 128, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,*,d_model,num_heads,dff,dropout_rate=0.1):\n",
        "    super(DecoderLayer,self).__init__()\n",
        "\n",
        "    self.causal_self_attention = CausalSelfAttention(\n",
        "        num_heads = num_heads,\n",
        "        key_dim = d_model,\n",
        "        dropout = dropout_rate\n",
        "    )\n",
        "\n",
        "    self.cross_attention = CrossAttention(\n",
        "        num_heads = num_heads,\n",
        "        key_dim = d_model,\n",
        "        dropout = dropout_rate\n",
        "    )\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x, context):\n",
        "    x = self.causal_self_attention(x=x)\n",
        "    x = self.cross_attention(x=x, context=context)\n",
        "\n",
        "    # Cache last attention scores for plotting later\n",
        "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
        "\n",
        "    x = self.ffn(x) # Shape `(batch_size, seq_len, d_model)`\n",
        "    return x"
      ],
      "metadata": {
        "id": "WAaVdSSAU2NA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_decoder_layer = DecoderLayer(d_model=512, num_heads=8, dff=2048)\n",
        "\n",
        "sample_decoder_layer_output = sample_decoder_layer(x=te_emb, context=in_emb)\n",
        "\n",
        "print(te_emb.shape)\n",
        "print(in_emb.shape)\n",
        "print(sample_decoder_layer_output.shape) # `(batch_size, seq_len, d_model)`"
      ],
      "metadata": {
        "id": "dWrc5yzTYmjm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "622c879e-151a-43f7-926d-40684645a7a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 128, 512)\n",
            "(64, 128, 512)\n",
            "(64, 128, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self,*,num_layers, d_model, num_heads, dff, vocab_size, dropout_rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size, d_model=d_model)\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "    self.dec_layers = [\n",
        "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
        "                     dff=dff, dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)\n",
        "    ]\n",
        "    self.last_attn_scores = None\n",
        "\n",
        "  def call(self, x, context):\n",
        "    # `x` is token-IDs shape (batch, target_seq_len)\n",
        "    x = self.pos_embedding(x) # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.dec_layers[i](x,context)\n",
        "\n",
        "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
        "\n",
        "    # shape of x is (batch_size, target_seq_len, d_model)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "9SnFsXHNM7MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_decoder = Decoder(num_layers=4, d_model=512, num_heads=8,\n",
        "                         dff=2048, vocab_size=vocab_size)\n",
        "\n",
        "output = sample_decoder(x=teacher, context=in_emb)\n",
        "\n",
        "print(teacher.shape)\n",
        "print(in_emb.shape)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEugWQp3fimJ",
        "outputId": "7dd5cac3-f581-4d6f-c1e2-41c5f8baecc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 128)\n",
            "(64, 128, 512)\n",
            "(64, 128, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_decoder.last_attn_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3syvsrVgFKL",
        "outputId": "f3890c54-69df-4bcf-8a50-fcc868b493a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 8, 128, 128), dtype=float32, numpy=\n",
              "array([[[[0.0666575 , 0.06636824, 0.06678679, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.06661712, 0.06667682, 0.0665133 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.06665023, 0.06635889, 0.06676417, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.06671308, 0.06684019, 0.06685069, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.06643081, 0.06690039, 0.0667645 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.0668325 , 0.0670995 , 0.06680577, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.06657998, 0.06647265, 0.06663676, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.06657787, 0.06640379, 0.06658199, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.06647158, 0.06651493, 0.06665941, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.06653512, 0.06666664, 0.06676827, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.06651974, 0.06632893, 0.06693047, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.06646822, 0.06666301, 0.0668617 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.06683233, 0.06683961, 0.0668598 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.06674575, 0.06691057, 0.06676134, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.06665353, 0.06671305, 0.06702992, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.06661797, 0.06678342, 0.06625838, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.06656305, 0.06677283, 0.06684375, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.06636412, 0.06669787, 0.06660561, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]]],\n",
              "\n",
              "\n",
              "       [[[0.01882948, 0.01884609, 0.01882067, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.01887697, 0.01885112, 0.01879454, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.01885923, 0.01887555, 0.01892476, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.01885053, 0.01890409, 0.01885076, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.01877075, 0.01882759, 0.01884636, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.01885442, 0.01887033, 0.01889012, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.0188205 , 0.01884273, 0.0187708 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.01885791, 0.01887228, 0.01886229, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.01888383, 0.01880581, 0.01878867, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.01882162, 0.01882676, 0.01889097, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.01879307, 0.01879777, 0.01887972, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.01882209, 0.01881819, 0.01897764, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.01893027, 0.01886327, 0.01887203, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.0188986 , 0.0188722 , 0.01887438, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.01888763, 0.01885766, 0.0188621 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.01884085, 0.01888295, 0.01890768, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.01880048, 0.01892857, 0.01890628, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.01884424, 0.01889284, 0.01887878, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]]],\n",
              "\n",
              "\n",
              "       [[[0.14264055, 0.14275141, 0.14304952, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.14291431, 0.14345357, 0.14285722, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.14268787, 0.14293471, 0.1425901 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.14272712, 0.14359605, 0.14341319, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.14257202, 0.14313433, 0.14316222, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.14235623, 0.1430162 , 0.14319646, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.14281282, 0.14320892, 0.1426171 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.14278871, 0.14247614, 0.14318635, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.14383037, 0.14213489, 0.1429895 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.14259845, 0.143394  , 0.14239308, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.14210874, 0.14312299, 0.14252728, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.14209403, 0.14314583, 0.14272532, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.14321162, 0.14282335, 0.14288284, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.1432742 , 0.14290054, 0.1427676 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.14295557, 0.14263034, 0.14287095, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.14289483, 0.14334556, 0.14249317, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.14283971, 0.14275508, 0.14296153, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.14245594, 0.14284578, 0.14314541, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.04541646, 0.04545592, 0.04531384, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.04524632, 0.04542887, 0.0454766 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.04532807, 0.04561479, 0.04528539, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.04541697, 0.04526164, 0.04553705, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.04546337, 0.04523376, 0.04526499, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.04532063, 0.04543761, 0.04568024, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.04541623, 0.04558309, 0.04547863, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.04551267, 0.04521535, 0.04564708, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.04546513, 0.04554268, 0.0454017 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.04540958, 0.04547289, 0.04543029, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.04535446, 0.04560252, 0.04561331, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.04535579, 0.04558208, 0.04550011, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.04557037, 0.04537585, 0.04530174, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.04560756, 0.04539591, 0.04545734, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.04554438, 0.04554136, 0.04538311, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.04543457, 0.04550576, 0.04548453, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.04544385, 0.04539249, 0.04529452, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.04555377, 0.04537985, 0.04533448, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]]],\n",
              "\n",
              "\n",
              "       [[[0.03998445, 0.03985465, 0.03998147, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.03993098, 0.04002769, 0.03996343, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.04007144, 0.03992691, 0.03992743, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.03997447, 0.04015818, 0.03985256, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.03994364, 0.04013449, 0.03980646, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.03990859, 0.04008912, 0.03993291, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.03997475, 0.03989791, 0.03994946, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.04003956, 0.03994675, 0.0398217 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.04016625, 0.03982772, 0.04008425, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.03995248, 0.04009095, 0.04014774, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.0400194 , 0.04024855, 0.04008371, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.0399884 , 0.04027653, 0.04011981, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.04009409, 0.0400721 , 0.04005878, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.04006642, 0.04011228, 0.0400026 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.04015883, 0.03996044, 0.0401399 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.03999935, 0.03989393, 0.04002947, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.03979667, 0.03982963, 0.03984555, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.03993613, 0.04010199, 0.03989784, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]]],\n",
              "\n",
              "\n",
              "       [[[0.01720001, 0.01712603, 0.01724091, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.01718385, 0.01719728, 0.01719698, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.01715484, 0.01716447, 0.01721689, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.01722709, 0.01725716, 0.01719194, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.01716928, 0.01728765, 0.01723199, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.01714142, 0.01721787, 0.01718749, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.01721196, 0.01718567, 0.01720138, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.01722983, 0.01718536, 0.01725448, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.01722272, 0.01715047, 0.01714586, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.01720168, 0.01723415, 0.0171593 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.01721329, 0.01716501, 0.01717252, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.01723987, 0.01725727, 0.01720228, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.0172967 , 0.01729555, 0.01726962, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.01730414, 0.01734184, 0.01733582, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.01721948, 0.01726454, 0.01716341, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.01721999, 0.01726093, 0.0171728 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.01719695, 0.01724951, 0.01714852, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.01726529, 0.01730358, 0.01717698, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
        "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model, num_heads=num_heads,\n",
        "                           dff=dff, vocab_size=input_vocab_size, dropout_rate=dropout_rate)\n",
        "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model, num_heads=num_heads,\n",
        "                           dff=dff, vocab_size=target_vocab_size, dropout_rate=dropout_rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # To support Keras model '.fit', pass all inputs as first argument\n",
        "    context, x = inputs\n",
        "\n",
        "    context = self.encoder(context) # (batch_size, context_len, d_model)\n",
        "\n",
        "    x = self.decoder(x, context) # (batch_size, target_len, d_model)\n",
        "\n",
        "    logits = self.final_layer(x) # (batch_size, target_len, target_vocab_size)\n",
        "\n",
        "    try:\n",
        "      # Drop keras mask, so it doesn't scale losses/metrics\n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    # Return final output and attention weights\n",
        "    return logits"
      ],
      "metadata": {
        "id": "cJ54y09FgegC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters"
      ],
      "metadata": {
        "id": "DsECFvcbiyEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1"
      ],
      "metadata": {
        "id": "vtN0P31SiuF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "MUoyRRlXjAOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = Transformer(num_layers=num_layers, d_model=d_model, num_heads=num_heads,\n",
        "                          dff=dff, input_vocab_size=vocab_size, target_vocab_size=vocab_size,\n",
        "                          dropout_rate=dropout_rate)"
      ],
      "metadata": {
        "id": "rvLmL2v9i81z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = transformer((input,teacher))\n",
        "print(teacher.shape)\n",
        "print(input.shape)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKuqmIkDjVur",
        "outputId": "6bcac387-40ff-48ad-d537-26463429cb9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[   2 1006 2550 ...    0    0    0]\n",
            " [   2   50 1522 ...    0    0    0]\n",
            " [   2 1665   44 ...    0    0    0]\n",
            " ...\n",
            " [   2  998  996 ...    0    0    0]\n",
            " [   2 1009  987 ...    0    0    0]\n",
            " [   2 1006  990 ...    0    0    0]], shape=(64, 128), dtype=int64)\n",
            "(64, 128)\n",
            "(64, 128)\n",
            "(64, 128, 7682)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = transformer.decoder.dec_layers[-1].last_attn_scores\n",
        "print(attn_scores.shape) # batch, heads, target_seq, input_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5P2mBGmvTvX",
        "outputId": "de4b3c2b-a653-4bec-de78-9f9d39c71ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 8, 128, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JwM1rpYwAFo",
        "outputId": "78ac1567-8c69-465b-ae8d-0e444e2d4c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_1 (Encoder)         multiple                  3622144   \n",
            "                                                                 \n",
            " decoder_1 (Decoder)         multiple                  5733120   \n",
            "                                                                 \n",
            " dense_38 (Dense)            multiple                  990978    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10346242 (39.47 MB)\n",
            "Trainable params: 10346242 (39.47 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_token_vector = tf.argmax(output,axis=2)\n",
        "pred_token = tokenizer.detokenize(pred_token_vector)\n",
        "pred_phrases = tf.strings.reduce_join(pred_token,axis=1,separator=' ')\n",
        "print(pred_phrases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNxfYwexwCeO",
        "outputId": "83dee46a-0737-41e2-c985-ce8f7c85e619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'\\xca\\x99\\xe0\\xb2\\xa5 dang\\xe0\\xb2\\xa5\\xe0\\xb2\\xa5 wtfiest\\xf0\\x9f\\x91\\x8d \\xf0\\x9f\\x8c\\xb2 update \\xf0\\x9f\\x8d\\x8d todays \\xe4\\xb8\\x80 chills pace pace pace todays todays todays todays todays \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe mob mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1 seiso seiso seiso seiso seiso placement placementry seisojected strong heck heck shulker updatetifftifftifftifftiff speaking rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffufflla crying tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99\\xf0\\x9f\\xa5\\xba backlog archivededing wtfageage country \\xe9\\xa2\\xa8 \\xf0\\x9f\\xaa\\x98 f update \\xe6\\x99\\xafiam complaining\\xe5\\x8f\\x96 bee led\\xe3\\x83\\x8f f story\\xe3\\x83\\x8f bee young bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b bee \\xe6\\xa0\\xb9 bee\\xe3\\x81\\x8b 39 void \\xf0\\x9f\\xa5\\x82ant \\xe2\\x9c\\xa8\\xe3\\x81\\x8b professional f \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1\\xe2\\x9a\\xa1 f##ry placement placementry seisojectedjected heck heck heck updatetifftifftifftifftiff rule rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia rude rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 2023\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b 1m behind behind behinduffuffllalla tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 spoilers\\xe3\\x83\\x8f\\xf0\\x9f\\x8e\\x88\\xe0\\xb2\\xa5 \\xf0\\x9f\\xa4\\xa4 \\xf0\\x9f\\xa4\\x8c \\xf0\\x9f\\xa4\\x8c \\xf0\\x9f\\x98\\xa4 todays todays todays todays todays pace pace pace todays todays todays 1m todays \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9bgaffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1 seiso seiso seiso seiso seiso seiso placementry seisojected strong heck heck shulker updatetifftifftifftifftiff speaking rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffufflla crying tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 coincidence stayed engaging\\xe0\\xb2\\xa5 wtf heck\\xe6\\xad\\x8c among \\xe9\\xa2\\xa8 f mogu update beevated coincidence\\xe2\\x9c\\x8a amnesia\\xe5\\x8f\\x96 apart bee expand sugar\\xe3\\x83\\x83 bee \\xe6\\xa0\\xb9 bee bee bee bee bee \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe mob mob \\xe6\\xa0\\xb9 stomach seiso \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso placement placementry seisojectedjected heck heck heck updatetifftifftifftifftiff rule rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffuffllalla tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 kobo\\xe0\\xb2\\xa5 engaging\\xe0\\xb2\\xa5eding want \\xf0\\x9f\\xa4\\x8c \\xf0\\x9f\\x98\\xa4 todays todays todays todays todays pace pace pace todays todays todays todays todays \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1 seiso seiso seiso seiso seiso seiso placementry seisojected strong heck heck shulker updatetifftifftifftifftiff speaking rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffufflla crying tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 energetic stayed country feeding want wtfph \\xf0\\x9f\\x8c\\xb2 f \\xf0\\x9f\\xaa\\x98 todays todays todays pace pace pace todays todays todays 1m todays \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1 seiso seiso seiso seiso seiso seiso placementry seisojected strong heck heck shulker updatetifftifftifftifftiff speaking rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffufflla crying tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 starts bee\\xe0\\xb2\\xa5 bee metal\\xf0\\x9f\\x8e\\x88 f\\xf0\\x9f\\xa4\\xa7 extinct led bee beeog brotherhood rude however\\xe2\\x9c\\x8a\\xe2\\x9c\\x8a\\xe1\\xb4\\x97 f bee \\xe6\\xa0\\xb9\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe mob mob \\xe6\\xa0\\xb9 stomach seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso seiso placementry seisojectedjected heck heck shulker updatetifftifftifftifftiff speaking rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b 1m behind behinduffuffuffllalla tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 wow dang\\xe0\\xb2\\xa5\\xe0\\xb2\\xa5 wtf want\\xd8\\xa7\\xd8\\xa7 led \\xf0\\x9f\\x8d\\x8d\\xf0\\x9f\\x99\\x8c update2 brotherhoodet let bee\\xe7\\x9c\\xa0 f story elden bee bee bee archived bee bee bee bee bee \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso placement placementry seisojected strong heck heck heck updatetifftifftifftifftiff rule rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b 1m behind behinduffuffuffllalla tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 starts \\xe2\\x9b\\x8f\\xe0\\xb2\\xa5 enjoys metal \\xf0\\x9f\\xa4\\x8c \\xf0\\x9f\\xa4\\x8c \\xf0\\x9f\\x98\\xa4 cuteness todays todays todays todays pace pace pace todays todays todays 1m todays \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9bgaffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1 seiso seiso seiso seiso seiso seiso placementry seisojected strong heck heck shulker updatetifftifftifftifftiff speaking rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffufflla crying tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 starts\\xe0\\xb2\\xa5 engaging\\xe0\\xb2\\xa5\\xd8\\xa7\\xd8\\xa7 meta \\xf0\\x9f\\xa4\\x8c suddenits todays musical update brotherhood story pace\\xe5\\x90\\x9b woof todays \\xe4\\xbc\\x9a\\xe1\\xb4\\x97ram brave bee bee bee bee bee bee bee bpm \\xe2\\x8c\\x9b under hit bee competitive\\xe3\\x81\\x8b update beeant\\xe1\\xb4\\x97 seiso \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1 wrenchlogical professional\\xe5\\x90\\x9b track potato beery\\xe5\\x90\\x9bjected thx heck heck heck updatetifftifftifftifftiff rule rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia rude rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 2023\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b 1m behind behind behinduffuffllalla behind tree tail tail tail tail behind behind behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99\\xf0\\x9f\\xa5\\xba yabai engaging metal\\xd8\\xa7 1mage\\xe4\\xbc\\x9a todays\\xe5\\xa4\\xa7 issuesog update update bee\\xe5\\x9c\\xb0\\xe2\\x9c\\x8a\\xe2\\x9c\\x8a expand vs \\xe6\\xa0\\xb9 pure northernlion brave\\xe3\\x81\\x8b bee bee bee bee bee bee engaging hit engaging hit shots void woof void\\xe5\\xa4\\xa7 explains\\xe3\\x81\\x8b\\xe3\\x81\\x8b\\xe3\\x81\\x8b spooktober \\xf0\\x9f\\xa5\\x82 updatelogical \\xe2\\x9c\\xa8ual update explore?ry\\xe5\\x90\\x9b flip heck 2023\\xe5\\x90\\x9b f bee testing updatetainualual\\xe5\\x90\\x9b professional guessing want \\xe3\\x80\\x8e turned\\xf0\\x9f\\x90\\xba brave\\xf0\\x9f\\x90\\xba maybeual shes rude rule rude rude\\xe5\\xa4\\xb1 robot 2023\\xf0\\x9f\\x90\\x9b+\\xe7\\xb5\\x82 \\xf0\\x9f\\xa7\\xa0 \\xe9\\xab\\x98 \\xe3\\x80\\x8e \\xe9\\xab\\x98\\xe9\\x80\\xb2\\xe3\\x80\\x8d goddess\\xe2\\x9c\\x85 photo musical seiso professional performanceual helps pack managing\\xf0\\x9f\\x90\\x9b interest\\xf0\\x9f\\x90\\x9b \\xe6\\x9c\\x8d northernlion\\xf0\\x9f\\x90\\x9b twinberlla shoppinguryual tail musical tail e \\xf0\\x9f\\xa4\\xa3 behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a younger \\xf0\\x9f\\x8c\\x80'\n",
            " b'\\xca\\x99 stomach dang creators feeding wtf engaging \\xf0\\x9f\\xa4\\x8c \\xf0\\x9f\\x98\\xa4 todays todays todays todays todays pace pace pace todays todays todays 1m todays \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1 seiso seiso seiso seiso seiso seiso placementry seisojected strong heck heck shulker updatetifftifftifftifftiff pair rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffufflla crying tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 dawnguard yabai\\xe0\\xb2\\xa5 update\\xd8\\xa7\\xd8\\xa7 heck \\xf0\\x9f\\x98\\xa4 cuteness todays todays todays todays pace pace pace todays todays todays 1m todays \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1 seiso seiso seiso seiso seiso seiso placementry seisojected strong heck heck shulker updatetifftifftifftifftiff speaking rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffufflla crying tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99\\xe1\\x85\\xa9 engaging\\xe0\\xb2\\xa5 wtf wtf\\xd8\\xa7\\xe2\\x9a\\xa1 adventure \\xf0\\x9f\\x8d\\x8d led todays bee musical update bee mood subaruph judging\\xe3\\x83\\x8f \\xe3\\x82\\x92 sugar \\xe4\\xb8\\x80\\xf0\\x9f\\x8e\\xb5 young bee bee bee bee bee \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe mob mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso placement placementry seisojectedjected heck heck heck updatetifftifftifftifftiff rule rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffuffllalla tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 stomach\\xe0\\xb2\\xa5 engaging\\xe0\\xb2\\xa5 metal\\xf0\\x9f\\x8e\\x88iam extinct f \\xf0\\x9f\\x8d\\x8d bee opponent opponentorsmy let brotherhood\\xe7\\x89\\xb9 bee update# ionoram bee bee rule bee bee bee bee \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe mob mob \\xe6\\xa0\\xb9 stomach seiso \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso placement placementry seisojectedjected heck heck heck updatetifftifftifftifftiff pair rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behind behinduffuffllalla tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 spiral italian feeding\\xe0\\xb2\\xa5 metalass metal\\xf0\\x9f\\xa4\\xa7 \\xf0\\x9f\\x8d\\x8d wow beeog updateres brotherhood bee\\xe5\\x8f\\x96 explosive 1mberry f \\xe6\\xa0\\xb9 bee emotes brave bee bee beeram bee bee tuber hit operaffeffe mob mob \\xe6\\xa0\\xb9 stomach seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso placement placementry seisojectedjected heck heck heck updatetifftifftifftifftiff rule rule amnesia turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 2023\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffuffllalla tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 dawnguard \\xe3\\x81\\xbb engaging\\xe0\\xb2\\xa5 metal\\xd8\\xa7 \\xf0\\x9f\\xa4\\x8c marathon goddess update \\xf0\\x9f\\x8d\\x8d update update opponent\\xf0\\x9f\\x8e\\x8a spooktober\\xe3\\x83\\x8f mood\\xe1\\xb4\\x97 starts pure story bee\\xe3\\x81\\x8b braveram bee bee beeram bee \\xe2\\x9c\\xa8 hit \\xe6\\xa0\\xb9 opera etc mob shotsry shotslip team f \\xf0\\x9f\\xa5\\x82 animal \\xf0\\x9f\\xa5\\x82uffs\\xe7\\xb5\\x82 fualual beery\\xe5\\x90\\x9bjected brainrot heck heck heck\\xe5\\x90\\x9b\\xe5\\x90\\x9b rule update \\xe6\\xa0\\xb9tifftainual bee bee want shots miitopia\\xf0\\x9f\\x90\\xba heck \\xe9\\xa2\\xa8 bee\\xf0\\x9f\\x90\\xbaual sugar rude rude fes \\xe3\\x81\\xbb initial\\xe2\\x9a\\xa1 2023 photo\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x8c\\xb7 \\xe9\\xab\\x98 \\xf0\\x9f\\xa7\\xa0\\xe7\\x9c\\xa0 treats\\xf0\\x9f\\x90\\x9b christmas\\xe2\\x9c\\x8a \\xe9\\xa2\\xa8 hour voices\\xe5\\xa4\\xa7 shapingual instead episodes metal lots miitopia interest deal names twinmineakingury tail \\xf0\\x9f\\xa4\\xa3 tail\\xe9\\x80\\xb2 musical musical \\xe3\\x81\\xbb\\xf0\\x9f\\x8c\\xb7 \\xf0\\x9f\\xa4\\xa3 \\xf0\\x9f\\x8c\\x80 behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 ollie stories\\xe0\\xb2\\xa5 bee wtf \\xf0\\x9f\\xa4\\x8c \\xf0\\x9f\\xa4\\x8c \\xf0\\x9f\\x98\\xa4 todays todays todays todays todays pace pace pace todays todays todays 1m todays \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1 seiso seiso seiso seiso seiso seiso placementry seisojected strong heck heck shulker updatetifftifftifftifftiff speaking rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffufflla crying tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 starts\\xe0\\xb2\\xa5 engaging\\xe0\\xb2\\xa5 wtf \\xf0\\x9f\\xa4\\x8c\\xd8\\xa7\\xf0\\x9f\\x98\\x91 bee goddess extinct\\xe5\\xa4\\xa7 \\xe6\\xa0\\xb9 toes bee\\xe2\\x9c\\x8a let 1m 1mberry faunaversary bee \\xe6\\xa0\\xb9 bee young bee bee bee bee bee bee deal bee hit whyffe mob mob \\xe6\\xa0\\xb9 stomach seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso placement placementry seisojectedjected heck heck heck updatetifftifftifftifftiff rule rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b 1m behind behind behinduffuffllalla tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99\\xe5\\xa4\\xa7\\xe0\\xb2\\xa5 engaging\\xe0\\xb2\\xa5 metal update\\xd8\\xa7 \\xf0\\x9f\\xa4\\x8c \\xca\\x8f \\xf0\\x9f\\x8d\\x8d \\xf0\\x9f\\x90\\xb1 musicalog \\xe6\\x99\\xaf spooktober idols todays todays expand f \\xe4\\xbc\\x9a bee sugar\\xe3\\x81\\x8b bee bee bee bee bee bee bee tuber \\xe2\\x8c\\x9b molyffeffe mob mob \\xe6\\xa0\\xb9 seiso seiso \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso placement placementry seisojectedjected heck heck heck updatetifftifftifftifftiff rule rule amnesia turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffuffllalla tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 country stayed \\xe3\\x81\\xbb\\xe0\\xb2\\xa5 \\xf0\\x9f\\xa4\\xa4 sauce \\xf0\\x9f\\xa4\\x8c\\xe3\\x81\\xb8its extinct bee update brotherhood jump story bee mistakes emotes woofberry pure story window brave bee bee bee bee bee\\xe5\\x90\\x9b \\xe2\\x8c\\x9b \\xe2\\x9c\\xa8 tons hit\\xe5\\x90\\x9bffeffe mob \\xe6\\xa0\\xb9 update \\xf0\\x9f\\xa5\\x82\\xe3\\x81\\x8b armor o \\xf0\\x9f\\xa5\\x82 purpose\\xe2\\x9a\\xa1\\xe2\\x9a\\xa1 \\xe9\\xab\\x98 seiso seiso placement placementry seisojectedjected heck heck heck updatetifftifftifftifftiff rule rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 2023\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behind behinduffuffllalla behind tree tail tail tail tail behind behind behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 kobo dang fes\\xe0\\xb2\\xa5 beeiam \\xf0\\x9f\\xa4\\x8c bee \\xf0\\x9f\\x8d\\x8d bee bee update \\xe8\\x8f\\x9c \\xe6\\xa0\\xb9 props\\xe5\\xaf\\xbe bee\\xe5\\x90\\x9b issues expand pureram\\xe3\\x81\\x8b bee emotes bee bee bee bee bee \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe mob mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso seiso placementry seisojectedjected heck heck heck updatetifftifftifftifftiff pair rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffuffllalla tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 starts\\xe0\\xb2\\xa5 engaging\\xe0\\xb2\\xa5 wtf \\xf0\\x9f\\xa4\\xa4\\xd8\\xa7 \\xf0\\x9f\\xaa\\x98 hint extinct wow bee brotherhood emerald brotherhood spooktoberered woof 2023 expand \\xe4\\xbc\\x9a\\xe3\\x81\\x8bramvin bee bee bee bee bee mood \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe mob mob \\xe6\\xa0\\xb9 seiso seiso \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso placement placementry seisojectedjected heck heck heck updatetifftifftifftifftiff rule rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffuffllalla tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 \\xf0\\x9f\\x91\\x80 bee\\xe0\\xb2\\xa5\\xe0\\xb2\\xa5\\xd8\\xa7\\xd8\\xa7 1m \\xe9\\xa2\\xa8 f maiden update update brotherhood opera awhile pace\\xe7\\x9c\\xa0 bee expandberry story bee\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso placement placementry seisojected strong heck heck heck updatetifftifftifftifftiff speaking rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffufflla crying tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 starts beelied\\xe0\\xb2\\xa5\\xd8\\xa7\\xd8\\xa7 \\xf0\\x9f\\xa4\\x8c\\xf0\\x9f\\x98\\x8e goddess bee musical update todays bee bee update spooktober 1m 1m todays f \\xe6\\xa0\\xb9 issues bee brave bee bee bee bee\\xe5\\x90\\x9b \\xe2\\x9c\\xa8 tons why why bee opera shotsvin woofry\\xe3\\x81\\x8b\\xe1\\xb4\\x97 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xe4\\xbc\\x9a team\\xe1\\xb4\\x97 seiso seiso seiso seiso placement placementry seisojectedjected heck heck heck updatetifftifftifftifftiff rule rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia rude rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 2023\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behind behinduffuffllalla tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99\\xf0\\x9f\\xa5\\xba incredibly\\xe0\\xb2\\xa5 engaging wtfage \\xf0\\x9f\\xaa\\x98 \\xf0\\x9f\\xa4\\x8c \\xf0\\x9f\\x8d\\x8d\\xf0\\x9f\\x8e\\x89ill youngugh* punch\\xe2\\x9c\\x8a todays jam expand\\xe1\\xb4\\x97 professional \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso placement placementry seisojected strong heck heck shulker updatetifftifftifftifftiff speaking rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba eu wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffuffllalla tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99\\xe5\\xa4\\xa7\\xe0\\xb2\\xa5 country\\xe0\\xb2\\xa5 \\xf0\\x9f\\xa4\\xa4\\xe6\\xad\\x8c extinct extinct adventure\\xe5\\xa4\\xa7 \\xca\\x8fog \\xf0\\x9f\\xa7\\x80 complaining opera pace todays todays todays todays todays \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 stomach seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1 seiso seiso seiso seiso seiso seiso placementry seisojected strong heck heck shulker updatetifftifftifftifftiff pair rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffufflla crying tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99\\xe0\\xb2\\xa5 engaging\\xe0\\xb2\\xa5\\xe0\\xb2\\xa5 beeassberry \\xe9\\xa2\\xa8 \\xf0\\x9f\\x8d\\x8d f bee bee \\xe6\\x99\\xaf\\xe6\\xbe\\xa4 pace bee however expand\\xe1\\xb4\\x97 \\xe6\\xa0\\xb9 \\xe4\\xbc\\x9a bee\\xf0\\x9f\\x8e\\x89 emotes emotes bee bee bee bee bee bee bpm \\xe2\\x8c\\x9b molyffeffe mob mob \\xe6\\xa0\\xb9 stomach seiso \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso placement placementry seisojectedjected heck heck heck updatetifftifftifftifftiff rule rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b 1m behind behind behinduffuffllalla tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99\\xf0\\x9f\\xa5\\xba bee \\xe3\\x81\\xbb metal wtf bee \\xf0\\x9f\\xa4\\x8c f f\\xe5\\xa4\\xa7 \\xe2\\x9c\\xa8 \\xf0\\x9f\\x8d\\x8dvated subtitles complaining brotherhood woof especially\\xe5\\x8f\\x96 pure f bee\\xe5\\x90\\x9b young young bee bee bee bee bee 39 bpm tuberramram ears shots woof2 shots aww\\xe1\\xb4\\x97 faunaversary\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1\\xe2\\x9a\\xa1ick\\xe5\\xa4\\xa7 track punishedry? beery\\xe7\\x9c\\xa0\\xe5\\x90\\x9b\\xe5\\x90\\x9b\\xe5\\x90\\x9b\\xe5\\x90\\x9b bau update\\xe5\\x90\\x9b\\xe5\\xa4\\xa7tiffualualrow rule\\xe5\\x90\\x9b\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xe7\\x89\\xb9 hurts\\xf0\\x9f\\x90\\xba rule maybe update rude rude rude rude robot wow\\xe5\\x90\\x9b goddess sugar sugarual returning young*\\xe7\\x9c\\xa0\\xe2\\x9c\\x85\\xf0\\x9f\\x90\\x9b update professional update parents musical musical helps told told metal 1m interest behind tuber creates \\xf0\\x9f\\xa5\\x82\\xe3\\x81\\x8b \\xe4\\xb8\\x80ber example tail\\xe9\\x80\\xb2 example miitopiauryog behind behind \\xe1\\x86\\xaf musical musical \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99\\xf0\\x9f\\xa5\\xba engaging\\xe0\\xb2\\xa5\\xe3\\x81\\x8b wtf came \\xf0\\x9f\\xa4\\x8c \\xf0\\x9f\\xaa\\x98 f \\xf0\\x9f\\xaa\\x98 finger update wants subtitles bee\\xe2\\x9c\\x8a todays gympie\\xe3\\x83\\x8fberry f\\xe3\\x81\\x8bram emotes brave bee beeram bee bee tons\\xe1\\xb5\\x8e \\xe3\\x83\\x81 opera regularlyffe\\xe6\\xad\\x8c shots \\xe6\\xa0\\xb9 \\xe2\\x9c\\xa8 yes armor \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso placement placementry seisojectedjected heck heck heck updatetifftifftifftifftiff rule rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 2023\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b 1m behind behinduffuffuffllalla tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 starts\\xe0\\xb2\\xa5 engaging\\xe0\\xb2\\xa5\\xd8\\xa7 \\xf0\\x9f\\xa4\\xa4 \\xf0\\x9f\\xa4\\x8c sudden\\xf0\\x9f\\xa4\\xa7 bee fingerugh opponent idols beemy bee led todays 1m todays \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1 seiso seiso seiso seiso seiso placement placementry seisojected strong heck heck heck updatetifftifftifftifftiff pair rule amnesia turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffuffllalla tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 \\xe6\\x9c\\x8d stayed engaginglied 1m \\xf0\\x9f\\xa4\\x8c \\xf0\\x9f\\xa4\\x8c \\xf0\\x9f\\x98\\xa4 cuteness todays todays todays todays pace pace pace todays todays todays 1m todays \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1 seiso seiso seiso seiso seiso seiso placementry seisojected strong heck heck shulker updatetifftifftifftifftiff pair rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso helps\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffufflla crying tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 dawnguard coincidence engaging\\xe0\\xb2\\xa5 enjoys \\xf0\\x9f\\xa4\\xa4 \\xf0\\x9f\\xa4\\x8c \\xf0\\x9f\\xa4\\x8c\\xf0\\x9f\\xa4\\xa7 moly \\xe9\\xa2\\xa8 ridiculous* strongest pace bee todays todays todays todays todays \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe mob mob \\xe6\\xa0\\xb9 stomach seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso placement placementry seisojected strong heck heck shulker updatetifftifftifftifftiff speaking rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffufflla crying tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 dang bee\\xe0\\xb2\\xa5eding\\xe0\\xb2\\xa5 musicalberry \\xf0\\x9f\\x8d\\x8d f\\xe5\\xa4\\xa7 bee musical story relationships pace pace todays todays todays todays todays \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 stomach seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1 seiso seiso seiso seiso seiso seiso placementry seisojected strong heck heck shulker updatetifftifftifftifftiff pair rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffufflla crying tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 starts\\xe0\\xb2\\xa5 engaging reverse\\xd8\\xa7 \\xf0\\x9f\\xaa\\x98\\xd8\\xa7\\xf0\\x9f\\x98\\x8e update \\xf0\\x9f\\x8d\\x8d todays todays todays pace pace pace todays todays todays 1m todays \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1 seiso seiso seiso seiso seiso seiso placementry seisojected strong heck heck shulker updatetifftifftifftifftiff pair rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffufflla crying tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 metal bee\\xe0\\xb2\\xa5 \\xf0\\x9f\\xa4\\x8c\\xd8\\xa7ass heck \\xf0\\x9f\\xa4\\x8c \\xf0\\x9f\\x8c\\xb2 todays issues bee beeiam bee spooktober\\xe5\\xa4\\xa7 todays 1m 1m todaysram story todays bee young bee bee bee bee entire tuber hit doing hit\\xe7\\x9c\\xa0 shots mob ass yes \\xe2\\x9c\\xa8\\xe3\\x81\\x8b\\xe1\\xb4\\x97 \\xe5\\xae\\x88 \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1\\xe7\\xb5\\x82 update \\xe9\\xab\\x98\\xe1\\xb4\\x97\\xe9\\xa0\\x91 seiso potato\\xe5\\x90\\x9bjected\\xe3\\x81\\x8b seisojected\\xe5\\x90\\x9b woof\\xe5\\x90\\x9b update\\xe5\\xa4\\xa7tifftain returning\\xe5\\x90\\x9b returning rule shotsant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia rude rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 2023\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b 1m behind behinduffuffuffllalla behind tree tail tail tail tail behind behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 starts\\xe0\\xb2\\xa5\\xe0\\xb2\\xa5eding\\xd8\\xa7\\xd8\\xa7 \\xf0\\x9f\\xa4\\x8c\\xf0\\x9f\\x98\\x8e \\xf0\\x9f\\x8d\\x8d bee todays todays todays pace pace pace todays todays todays 1m todays \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1 seiso seiso seiso seiso seiso seiso placementry seisojected strong heck heck shulker updatetifftifftifftifftiff pair rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffufflla crying tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99\\xe0\\xb2\\xa5 engaging\\xe0\\xb2\\xa5 spiral\\xd8\\xa7 want meta meta\\xf0\\x9f\\xa4\\xa7 \\xf0\\x9f\\x8d\\x8d musical musical bee punchiam billy reminder todays behind\\xe3\\x83\\x8fleyley brave young bee bee bee bee bee bee \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe mob mob \\xe6\\xa0\\xb9 seiso seiso \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso placement placementry seisojectedjected heck heck heck updatetifftifftifftifftiff pair rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behind behinduffuffllalla tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 starts\\xe0\\xb2\\xa5 engaging\\xe0\\xb2\\xa5\\xd8\\xa7 meta \\xf0\\x9f\\xa4\\x8c \\xf0\\x9f\\xa4\\x8c \\xf0\\x9f\\x8d\\x8d f photo opponent \\xe4\\xbc\\x9a brotherhoodet todays\\xe2\\x9c\\x8a update bee expandley\\xe3\\x83\\x8f bee emotes goddess bee bee bee beeram bee tuber\\xe5\\xa4\\xa7 beef \\xe8\\x87\\xaa todays shots update2 returning armor\\xe5\\x90\\x9b \\xf0\\x9f\\xa5\\x82 wet \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso seiso placementry seisojectedjected heck heck heck updatetifftifftifftifftiff rule rule amnesia turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 2023\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b 1m behind behind behinduffuffllalla tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 dawnguard engaging\\xe0\\xb2\\xa5\\xe0\\xb2\\xa5 metalage attempts f bee \\xf0\\x9f\\xaa\\x98 bee updateog story\\xf0\\x9f\\x90\\xbamy todays\\xe2\\x9c\\x8a 1mberry\\xe3\\x81\\x8b mentioning brave raw incredibly bee bee bee bee bee tons bpm beef molyffeffe mob mob \\xe6\\xa0\\xb9 stomach seiso \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso placement placementry seisojectedjected heck heck heck updatetifftifftifftifftiff rule rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behind behinduffuffllalla tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 spiral bee spiral\\xe0\\xb2\\xa5 1m \\xf0\\x9f\\xa4\\x8c \\xf0\\x9f\\xa4\\x8c \\xf0\\x9f\\x98\\xa4 todays todays todays todays todays pace pace pace todays todays todays 1m todays \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1 seiso seiso seiso seiso seiso seiso placementry seisojected strong heck heck shulker updatetifftifftifftifftiff pair rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso helps\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffufflla crying tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 bee\\xf0\\x9f\\x8e\\x88 engaging engaging bee five jet extinct \\xf0\\x9f\\x8d\\x8d\\xe5\\xa4\\xa7 bee\\xe5\\xa4\\xa7iam opera bee awhile outcome\\xe5\\x8f\\x96 todays 120 \\xe4\\xbc\\x9a issues\\xe3\\x81\\x8b mentioning 120 bee bee bee bee bee hit regularly\\xe7\\x9c\\xa0 etc opera\\xe7\\x9c\\xa0ffe updatevin \\xe2\\x9c\\xa8ant \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82ra animal\\xe2\\x9a\\xa1 bee\\xe1\\xb4\\x97 bee update punished \\xe3\\x81\\xbb beery makejectedjected heck heck heck updatetifftifftifftifftiff rule rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia rude rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 2023\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b 1m behind behind behinduffuffllalla behind tree tail tail tail tail behind behind behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 dawnguard \\xe3\\x81\\xbb\\xe0\\xb2\\xa5 engaging metal \\xf0\\x9f\\xa4\\xa4berry25 f todays roof beeugh child grind\\xe2\\x9c\\x8a pacern judging pure bee \\xf0\\x9f\\x99\\x8a brave \\xf0\\x9f\\x8c\\xbf bee bee bee bee beeram brave \\xe2\\x8c\\x9b \\xe2\\x9c\\xa8 bee etc bee bee shotsvin bee bee \\xf0\\x9f\\xa5\\x82\\xe1\\xb4\\x97\\xe3\\x81\\x8b frustrated \\xf0\\x9f\\xa4\\xa3ual\\xe1\\xb4\\x97 bee\\xe5\\x90\\x9b punished \\xe6\\x9c\\x8diction update update update twin twin heck\\xe5\\x90\\x9b testing updatetiff recently\\xe9\\x80\\xb2ual professional everything \\xe3\\x80\\x8e want want want\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia rude rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 2023\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x91\\x8d pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0 1m behind behind behinduffuffllalla behind tree tail tail tail tail behind behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99\\xf0\\x9f\\xa5\\xba engaging\\xe0\\xb2\\xa5\\xe0\\xb2\\xa5uffs update \\xf0\\x9f\\xa4\\x8c\\xe3\\x81\\xb8 f \\xf0\\x9f\\xaa\\x98\\xe5\\x90\\x9b opponent todays pace pace pace todays todays todays todays todays \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1 seiso seiso seiso seiso seiso seiso placementry seisojected strong heck heck shulker updatetifftifftifftifftiff pair rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffufflla crying tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 dawnguard engaging\\xe0\\xb2\\xa5\\xe0\\xb2\\xa5 \\xf0\\x9f\\xa4\\xa4 wtf jet \\xf0\\x9f\\x98\\xa4 todays todays todays todays todays pace pace pace todays todays todays 1m todays \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1 seiso seiso seiso seiso seiso seiso placementry seisojected strong heck heck shulker updatetifftifftifftifftiff pair rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso helps\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffufflla crying tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99\\xe5\\xa4\\xa7\\xe3\\x83\\x8f\\xe0\\xb2\\xa5\\xe0\\xb2\\xa5 wtf\\xd8\\xa7 \\xf0\\x9f\\x8d\\x8d \\xf0\\x9f\\x98\\xa4 cuteness todays todays todays todays pace pace pace todays todays todays 1m todays \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1 seiso seiso seiso seiso seiso seiso placementry seisojected strong heck heck shulker updatetifftifftifftifftiff pair rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffufflla crying tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99\\xe1\\x85\\xa9 dang\\xe0\\xb2\\xa5 engaging \\xf0\\x9f\\xa4\\x8c metal \\xf0\\x9f\\xa4\\x8c \\xf0\\x9f\\x98\\xa4 todays todays todays todays todays pace pace pace todays todays todays todays todays \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1 seiso seiso seiso seiso seiso seiso placementry seisojected strong heck heck shulker updatetifftifftifftifftiff pair rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffufflla crying tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99\\xf0\\x9f\\xa5\\xba dang feeding\\xe0\\xb2\\xa5 1m \\xf0\\x9f\\xa4\\x8c \\xf0\\x9f\\xa4\\x8c \\xf0\\x9f\\x98\\xa4 todays todays todays todays todays pace pace pace todays todays todays 1m todays \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1 seiso seiso seiso seiso seiso seiso placementry seisojected strong heck heck shulker updatetifftifftifftifftiff pair rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffufflla crying tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 starts\\xe0\\xb2\\xa5\\xe0\\xb2\\xa5og wtf\\xd8\\xa7\\xd8\\xa7berry\\xe5\\xa4\\xa7 sudden\\xe5\\xa4\\xa7 bee bee update brotherhood bee subaru led 1m woof 2023 story bee brave bee todays bee bee beeram tonsram \\xe2\\x9c\\xa8 bee bee\\xe3\\x81\\x8b mob void baby stomach seiso \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso placement placementry seisojectedjected heck heck heck updatetifftifftifftifftiff rule rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia rude rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 2023\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b 1m behind behind behinduffuffllalla tree tree tail tail tail tail tail behind behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 decent tonight engaging wtf wtf\\xd8\\xa7 start \\xf0\\x9f\\x8d\\x8d \\xe6\\xa0\\xb9ill ledding\\xe6\\xbe\\xa4 \\xf0\\x9f\\x97\\xa1 mood\\xe5\\xaf\\xbe however \\xf0\\x9f\\xab\\x82berry fubuki \\xf0\\x9f\\x99\\x8a \\xe6\\xa0\\xb9 bee bee however bee bee bee bee bee\\xe5\\x90\\x9b bpm under tuberffeffe mob mob \\xe6\\xa0\\xb9 stomach seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso placement placementry seisojectedjected heck heck heck updatetifftifftifftifftiff rule rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behind behinduffuffllalla tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 starts\\xe0\\xb2\\xa5 incredibly\\xe0\\xb2\\xa5 engaging\\xe6\\xad\\x8c \\xf0\\x9f\\x98\\xa4 \\xf0\\x9f\\x8c\\xb2 bee bee \\xf0\\x9f\\xaa\\x98 beeres brotherhood brotherhood outcome subaru todays expand 2023 iono story pure bee incredibly bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso placement placementry seisojected strong heck heck heck updatetifftifftifftifftiff pair rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffuffllalla tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 \\xca\\x99 spoilers\\xe0\\xb2\\xa5\\xe0\\xb2\\xa5berry\\xe6\\xad\\x8c\\xf0\\x9f\\x98\\x91berry goddess goddess bee update musical opera opera strongest bee mistakes f elden story pure bee emotes goddess bee bee bee bee bee bee engaging engaging bee beeffe bee baby\\xe3\\x81\\x8b wtf bee\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82\\xe3\\x81\\x8b\\xe2\\x9a\\xa1\\xe2\\x9a\\xa131\\xe1\\xb4\\x97 scuffed punishedmine placementry seisojectedjected heck heck heck updatetifftifftifftifftiff rule rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia rude rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 2023\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b 1m behind behind behinduffuffllalla behind tree tail tail tail tail behind behind behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 starts\\xe0\\xb2\\xa5 engaging\\xe0\\xb2\\xa5\\xd8\\xa7 \\xf0\\x9f\\xa4\\xa4 \\xf0\\x9f\\xaa\\x98 heck extinct \\xf0\\x9f\\x8d\\x8d\\xe5\\xa4\\xa7 opponent bee 120my\\xe5\\xaf\\xbe amnesiamy\\xe3\\x83\\x8f 1m \\xe4\\xbc\\x9aram mentioning mentioning bee bee bee bee bee bee engaging \\xe2\\x8c\\x9b under opera operaffeen void explains wtf seiso \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso placement placementry seisojectedjected heck heck heck updatetifftifftifftifftiff rule rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia rude rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 2023\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b 1m behind behind behinduffuffllalla tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 dang\\xe0\\xb2\\xa5 engaging wtf\\xe0\\xb2\\xa5iamage \\xf0\\x9f\\x8c\\xb2 led \\xf0\\x9f\\x8c\\xb2\\xe5\\x90\\x9b bee\\xe2\\x9c\\x85 pace pace pace todays todays todays 1m todays \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1 seiso seiso seiso seiso seiso placement placementry seisojected strong heck heck shulker updatetifftifftifftifftiff speaking rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffufflla crying tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 spiral\\xe0\\xb2\\xa5 \\xe3\\x81\\xbb wtf\\xe0\\xb2\\xa5\\xd8\\xa7 wtf \\xf0\\x9f\\xa4\\x8c \\xf0\\x9f\\x8d\\x8d competition\\xe5\\xa4\\xa7 brotherhood \\xf0\\x9f\\xa5\\x82\\xe3\\x83\\x8f complaining let spooktober led woof expand \\xe4\\xbc\\x9a goddessmatic bee emotes bee bee bee bee bee bee bpm youngantsjected bee shots why update beeant aww playing \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 tm\\xe7\\xb5\\x82\\xe5\\x90\\x9b seiso seiso seiso placement placementry seisojectedjected heck heck heck updatetifftifftifftifftiff rule rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia rude rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 2023\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behind behinduffuffllalla tree tree tail tail tail tail tail behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 dawnguard engaging bee\\xe0\\xb2\\xa5eding \\xf0\\x9f\\xa4\\x8c\\xe2\\x9c\\x8a let f bee\\xe5\\x90\\x9b update todays pace pace pace todays todays todays todays todays \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1 seiso seiso seiso seiso seiso seiso placementry seisojected strong heck heck shulker updatetifftifftifftifftiff speaking rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffufflla crying tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 metal\\xe0\\xb2\\xa5 engaging\\xe0\\xb2\\xa5 wtf wtfph \\xf0\\x9f\\x8c\\xb2 \\xf0\\x9f\\x8d\\x8d goddess ridiculous update opponent warden propsmy\\xe2\\x9c\\x8a led update \\xe4\\xbc\\x9a window pure bee bee archived bee bee bee bee bee tonsants beefjected opera bee bee\\xe3\\x81\\x8b \\xe6\\xa0\\xb9 himselfisible\\xe3\\x81\\x8b\\xe1\\xb4\\x97 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso placement placementry seisojectedjected heck heck heck updatetifftifftifftifftiff rule rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba eu wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 2023\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b 1m behind behind behinduffuffllalla tree tree tail tail tail tail tail behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99ph \\xe3\\x81\\xbb \\xf0\\x9f\\xa5\\x82 italian engaging metal \\xf0\\x9f\\x8d\\x8d\\xd8\\xa7\\xf0\\x9f\\xa4\\xa7 update sudden brotherhood bee ridiculous awhile bee however 1m\\xe5\\xa4\\xa7 expand expand\\xf0\\x9f\\x8e\\xb5ramvin young bee bee bee bee bee why \\xe2\\x9c\\xa8 beef bee\\xe7\\x9c\\xa0 bee truck woof update\\xe3\\x83\\x9e wtf \\xe2\\x9c\\xa8\\xe3\\x81\\x8b f f spooktober bee\\xe5\\x90\\x9b\\xe1\\xb4\\x97\\xe5\\x90\\x9b update potatory bee\\xe5\\x90\\x9b\\xe5\\x90\\x9b heck testing\\xe5\\x90\\x9b update update\\xe5\\xa4\\xa7tiff\\xe2\\x9a\\xa1 \\xe6\\xa0\\xb9 review\\xe5\\x90\\x8c \\xe8\\x8f\\x9c rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia rude rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 2023\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b 1m behind behind behinduffuffllalla behind tree tail tail tail tail tail behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 country metal\\xe0\\xb2\\xa5\\xe0\\xb2\\xa5 wtf foxantic \\xf0\\x9f\\xa4\\x8c \\xf0\\x9f\\xaa\\x98 windowits \\xe8\\x8f\\x9c todays pace pace pace todays todays todays todays todays \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe mob mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82\\xe2\\x9a\\xa1 seiso seiso seiso seiso seiso placement placementry seisojected strong heck heck shulker updatetifftifftifftifftiff speaking rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffufflla crying tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99\\xf0\\x9f\\xa5\\xba incredibly\\xe0\\xb2\\xa5\\xe0\\xb2\\xa5 metal\\xd8\\xa7 \\xf0\\x9f\\x8d\\x8d \\xf0\\x9f\\x8d\\x8d f \\xf0\\x9f\\x8c\\xb2 f bee \\xe6\\xa0\\xb9 complaining bee massage bee todays\\xe3\\x83\\x8f \\xe6\\xa0\\xb9 bee bee mentioning\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe mob mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso placement placementry seisojected strong heck heck heck updatetifftifftifftifftiff speaking rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffuffllalla tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99\\xe0\\xb2\\xa5 engaging spiral engaging placeberry \\xf0\\x9f\\xa4\\x8c \\xf0\\x9f\\xaa\\x98 update\\xe5\\xa4\\xa7 \\xf0\\x9f\\xaa\\x98 \\xe6\\xa0\\xb9 musical bee spooktober however\\xe5\\xa4\\xa7 update update story pureram \\xe4\\xb8\\x80\\xf0\\x9f\\x8e\\xb5 bee bee bee bee bee bee \\xe3\\x83\\x81 tuber hit tuberffeffe mob mob \\xe6\\xa0\\xb9 stomach seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso placement placementry seisojectedjected heck heck heck updatetifftifftifftifftiff speaking rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behind behinduffuffllalla tree tree tail tail tail tail tail behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99ph engaging\\xe0\\xb2\\xa5 italian italianberry \\xf0\\x9f\\x8d\\x8d\\xd8\\xa7 \\xf0\\x9f\\x8d\\x8dits \\xf0\\x9f\\x90\\xb1 argue\\xe5\\xa4\\xa7 update bee story pace\\xe5\\x90\\x9b update expand todays \\xf0\\x9f\\x99\\x8a\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe\\xe3\\x81\\x8b mob \\xe6\\xa0\\xb9 seiso seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso placement placementry seisojected strong heck heck shulker updatetifftifftifftifftiff speaking rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behinduffuffuffllalla tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99 starts\\xe0\\xb2\\xa5\\xe0\\xb2\\xa5 wtf engaging metal 1m\\xd8\\xa7 todays \\xe9\\xa2\\xa8 bee opponent bee relationships bee bee brotherhood\\xe5\\xa4\\xa7 expand bee expand window\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee \\xe2\\x9c\\xa8 \\xe2\\x8c\\x9b \\xe2\\x8c\\x9b molyffeffe mob mob \\xe6\\xa0\\xb9 stomach seiso\\xe3\\x81\\x8b \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 \\xf0\\x9f\\xa5\\x82 seiso seiso seiso seiso seiso placement placementry seisojected strong heck heck shulker updatetifftifftifftifftiff speaking rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia wow rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 seiso\\xf0\\x9f\\x90\\x9b seiso seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b behind behind behinduffuffllalla tree tree tail tail tail tail \\xe7\\x9a\\xae behind behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'\n",
            " b'\\xca\\x99\\xe0\\xb2\\xa5 engaging country engaging\\xd8\\xa7 \\xf0\\x9f\\xa4\\x8c jet \\xf0\\x9f\\xa4\\x8c sudden bee joke musical subtitles\\xe6\\xbe\\xa4* pace\\xe2\\x9c\\x8a todays f elden\\xe3\\x83\\x8f\\xe3\\x81\\x8b\\xe3\\x81\\x8b bee bee bee bee bee bee bee \\xe3\\x83\\x81 \\xe2\\x8c\\x9b tons\\xe5\\x90\\x9b\\xe7\\x9c\\xa0 etcffe update woofry \\xf0\\x9f\\xa5\\x82\\xe1\\xb4\\x97 faunaversary f \\xf0\\x9f\\xa5\\x82logical 2023# shotsual younger testing bee explains\\xe5\\x90\\x9bjectedjected heck heck heck updatetifftifftifftifftiff rule rule rule turnedant turned\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba\\xf0\\x9f\\x90\\xba amnesia rude rude rude\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d\\xf0\\x9f\\x91\\x8d 2023 2023\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b seiso seiso\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b\\xf0\\x9f\\x90\\x9b pair pair seiso seiso seiso seiso chapter\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0\\xe7\\x9c\\xa0 1m behind behinduffuffuffllalla tree tree tail tail tail tail tail behind behind behind behind \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a \\xf0\\x9f\\x99\\x8a'], shape=(64,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = tf.Variable(\n",
        "[b'40ized got cards \\xf0\\x9f\\x92\\x94 above \\xf0\\x9f\\x92\\x94 attacked es watchalong\\xe7\\x92\\xb0 summon summon showsgogogogogogogogo stuck stuck stuck stuck\\xe5\\x84\\xaa\\xe5\\x84\\xaarasedingedinggogo\\xf0\\x9f\\xa5\\xa5\\xf0\\x9f\\xa5\\xa5\\xf0\\x9f\\xa5\\xa5\\xf0\\x9f\\xa5\\x95\\xf0\\x9f\\xa5\\x95gogh \\xf0\\x9f\\x92\\x94 \\xf0\\x9f\\x92\\x94 heartbeat\\xf0\\x9f\\xa5\\x95gogogogo \\xe1\\x84\\x92 \\xe1\\x84\\x92edingedingeding\\xe3\\x83\\xaa\\xe3\\x83\\xaa\\xe3\\x83\\xaarayray\\xe3\\x83\\xaa\\xe3\\x83\\xaa# platform platform platformedingeding#go near near noise \\xe1\\x84\\x92 \\xe1\\x84\\x92 \\xe1\\x84\\x92 \\xe1\\x84\\x92 \\xe1\\x84\\x92 \\xe1\\x84\\x92 \\xe1\\x84\\x92 \\xe1\\x84\\x92gogogogogogogoedingedinggo\\xe3\\x83\\xaa\\xe3\\x83\\xaa robot robot robot plane plane color \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 bounce\\xe3\\x80\\x8e\\xe3\\x80\\x8e \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 heartbeat heartbeat \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xf0\\x9f\\x8c\\x88 \\xf0\\x9f\\x8c\\x88 \\xf0\\x9f\\x8c\\x88 \\xe1\\x84\\x92\\xe8\\xb6\\xb3 heartbeat',\n",
        " b'##edingannereding sweepzzy \\xf0\\x9f\\x92\\x94\\xe7\\x81\\xab attacked attacked attackedndingnding summonndingnding horrible\\xe6\\x9c\\xaa wholesome stucknding stuck stuck stuck stuck \\xe4\\xbf\\xa1 stuckzzy honest \\xf0\\x9f\\x98\\x8ceding \\xe4\\xbf\\xa1 \\xe4\\xbf\\xa1nding yupedingedingeding \\xe7\\xa7\\x81\\xe5\\x84\\xaa \\xe1\\x84\\x92 \\xf0\\x9f\\xa4\\x8e mythzzyedingnding going \\xe1\\x84\\x92 \\xe1\\x84\\x92eding ost mythedingeding\\xe3\\x83\\xaa\\xe3\\x83\\xaa\\xe3\\x83\\xaarayray\\xe3\\x83\\xaa\\xe3\\x83\\xaa# platform platform platformedingeding# near near near noise \\xe1\\x84\\x92 \\xe1\\x84\\x92 \\xe1\\x84\\x92 \\xe1\\x84\\x92 \\xe1\\x84\\x92 \\xe1\\x84\\x92 \\xe1\\x84\\x92 \\xe1\\x84\\x92gogogogo\\xe3\\x83\\xaa\\xe3\\x83\\xaaedingedingedinggo\\xe3\\x83\\xaa \\xe3\\x81\\x95 robot robot robot robot robot color \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 bounce\\xe3\\x80\\x8e\\xe3\\x80\\x8e \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 heartbeat heartbeat \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xe3\\x81\\x95 \\xf0\\x9f\\x8c\\x88 \\xf0\\x9f\\x8c\\x88 \\xf0\\x9f\\x8c\\x88 \\xe1\\x84\\x92\\xe8\\xb6\\xb3 heartbeat'])\n"
      ],
      "metadata": {
        "id": "KhmkDs27cvy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for codes in pred:\n",
        "  print(codes.numpy().decode())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDlzjq4sh1e7",
        "outputId": "e10be97f-832d-4eca-f4a4-a0f3955d13e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40ized got cards 💔 above 💔 attacked es watchalong環 summon summon showsgogogogogogogogo stuck stuck stuck stuck優優rasedingedinggogo🥥🥥🥥🥕🥕gogh 💔 💔 heartbeat🥕gogogogo ᄒ ᄒedingedingedingリリリrayrayリリ# platform platform platformedingeding#go near near noise ᄒ ᄒ ᄒ ᄒ ᄒ ᄒ ᄒ ᄒgogogogogogogoedingedinggoリリ robot robot robot plane plane color さ さ さ さ さ さ さ bounce『『 さ さ さ heartbeat heartbeat さ さ さ さ さ さ さ さ さ さ 🌈 🌈 🌈 ᄒ足 heartbeat\n",
            "##edingannereding sweepzzy 💔火 attacked attacked attackedndingnding summonndingnding horrible未 wholesome stucknding stuck stuck stuck stuck 信 stuckzzy honest 😌eding 信 信nding yupedingedingeding 私優 ᄒ 🤎 mythzzyedingnding going ᄒ ᄒeding ost mythedingedingリリリrayrayリリ# platform platform platformedingeding# near near near noise ᄒ ᄒ ᄒ ᄒ ᄒ ᄒ ᄒ ᄒgogogogoリリedingedingedinggoリ さ robot robot robot robot robot color さ さ さ さ さ さ さ bounce『『 さ さ さ heartbeat heartbeat さ さ さ さ さ さ さ さ さ さ 🌈 🌈 🌈 ᄒ足 heartbeat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "Uses Adam optimizer with original [Transformer paper](https://arxiv.org/abs/1706.03762) custom learning rate scheduler.\n",
        "\n",
        "$$lrate = d_{model}^{-0.5}*\\min\\left(step_{num}^{-0.5},step_{num}*warmup\\_steps^{-1.5}\\right)$$"
      ],
      "metadata": {
        "id": "TrPSjYbf1Gsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, dtype=tf.float32)\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
      ],
      "metadata": {
        "id": "5RDe4LkzyGoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9,\n",
        "                                     beta_2=0.98, epsilon=1e-9)"
      ],
      "metadata": {
        "id": "D6e28oFoP7jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup padding mask for calculating loss properly\n",
        "def masked_loss(label, pred):\n",
        "  mask = label != 0\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none'\n",
        "  )\n",
        "  loss = loss_object(label,pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)\n",
        "  loss *= mask\n",
        "\n",
        "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "  return loss\n",
        "\n",
        "def masked_accuracy(label, pred):\n",
        "  pred = tf.argmax(pred, axis=2)\n",
        "  label = tf.cast(label, pred.dtype)\n",
        "  match = label == pred\n",
        "\n",
        "  mask = label != 0\n",
        "\n",
        "  match = match & mask\n",
        "\n",
        "  match = tf.cast(match, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "j8e3YTkJRLbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.compile(loss=masked_loss, optimizer=optimizer,\n",
        "                    metrics=[masked_accuracy])"
      ],
      "metadata": {
        "id": "eXbzm1U9T89v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.fit(train_batches, epochs=20, validation_data=val_batches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCDHhuTPUJ_z",
        "outputId": "2ae3df04-d9cc-4cc7-ec88-3a471b1b3d67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "700/700 [==============================] - 297s 379ms/step - loss: 6.7696 - masked_accuracy: 0.1075 - val_loss: 4.8312 - val_masked_accuracy: 0.3064\n",
            "Epoch 2/20\n",
            "700/700 [==============================] - 257s 368ms/step - loss: 3.5250 - masked_accuracy: 0.4673 - val_loss: 2.1439 - val_masked_accuracy: 0.6832\n",
            "Epoch 3/20\n",
            "700/700 [==============================] - 257s 367ms/step - loss: 1.7309 - masked_accuracy: 0.7268 - val_loss: 0.9192 - val_masked_accuracy: 0.8642\n",
            "Epoch 4/20\n",
            "700/700 [==============================] - 260s 372ms/step - loss: 0.8637 - masked_accuracy: 0.8563 - val_loss: 0.3526 - val_masked_accuracy: 0.9498\n",
            "Epoch 5/20\n",
            "700/700 [==============================] - 258s 368ms/step - loss: 0.3285 - masked_accuracy: 0.9472 - val_loss: 0.1355 - val_masked_accuracy: 0.9840\n",
            "Epoch 6/20\n",
            "700/700 [==============================] - 258s 368ms/step - loss: 0.2012 - masked_accuracy: 0.9690 - val_loss: 0.1042 - val_masked_accuracy: 0.9881\n",
            "Epoch 7/20\n",
            "700/700 [==============================] - 258s 368ms/step - loss: 0.1403 - masked_accuracy: 0.9789 - val_loss: 0.0883 - val_masked_accuracy: 0.9901\n",
            "Epoch 8/20\n",
            "700/700 [==============================] - 258s 369ms/step - loss: 0.1090 - masked_accuracy: 0.9842 - val_loss: 0.0737 - val_masked_accuracy: 0.9920\n",
            "Epoch 9/20\n",
            "700/700 [==============================] - 259s 369ms/step - loss: 0.0907 - masked_accuracy: 0.9872 - val_loss: 0.0700 - val_masked_accuracy: 0.9927\n",
            "Epoch 10/20\n",
            "700/700 [==============================] - 257s 368ms/step - loss: 0.0768 - masked_accuracy: 0.9894 - val_loss: 0.0634 - val_masked_accuracy: 0.9938\n",
            "Epoch 11/20\n",
            "700/700 [==============================] - 261s 373ms/step - loss: 0.0647 - masked_accuracy: 0.9910 - val_loss: 0.0620 - val_masked_accuracy: 0.9942\n",
            "Epoch 12/20\n",
            "700/700 [==============================] - 257s 367ms/step - loss: 0.0569 - masked_accuracy: 0.9922 - val_loss: 0.0656 - val_masked_accuracy: 0.9941\n",
            "Epoch 13/20\n",
            "700/700 [==============================] - 255s 365ms/step - loss: 0.0495 - masked_accuracy: 0.9932 - val_loss: 0.0561 - val_masked_accuracy: 0.9946\n",
            "Epoch 14/20\n",
            "700/700 [==============================] - 261s 374ms/step - loss: 0.0446 - masked_accuracy: 0.9939 - val_loss: 0.0501 - val_masked_accuracy: 0.9952\n",
            "Epoch 15/20\n",
            "700/700 [==============================] - 261s 372ms/step - loss: 0.0401 - masked_accuracy: 0.9946 - val_loss: 0.0515 - val_masked_accuracy: 0.9950\n",
            "Epoch 16/20\n",
            "700/700 [==============================] - 260s 372ms/step - loss: 0.0374 - masked_accuracy: 0.9950 - val_loss: 0.0506 - val_masked_accuracy: 0.9954\n",
            "Epoch 17/20\n",
            "700/700 [==============================] - 257s 367ms/step - loss: 0.0324 - masked_accuracy: 0.9957 - val_loss: 0.0533 - val_masked_accuracy: 0.9956\n",
            "Epoch 18/20\n",
            "700/700 [==============================] - 257s 368ms/step - loss: 0.0327 - masked_accuracy: 0.9957 - val_loss: 0.0488 - val_masked_accuracy: 0.9959\n",
            "Epoch 19/20\n",
            "700/700 [==============================] - 259s 370ms/step - loss: 0.0304 - masked_accuracy: 0.9960 - val_loss: 0.0483 - val_masked_accuracy: 0.9958\n",
            "Epoch 20/20\n",
            "700/700 [==============================] - 259s 371ms/step - loss: 0.0282 - masked_accuracy: 0.9963 - val_loss: 0.0456 - val_masked_accuracy: 0.9958\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7edc18c37820>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving and loading model weights manually."
      ],
      "metadata": {
        "id": "1udyjLoUmaN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint_path = 'transformer_1'"
      ],
      "metadata": {
        "id": "2w-9N1gxmZNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save weights\n",
        "# transformer.save_weights(model_checkpoint_path)"
      ],
      "metadata": {
        "id": "QuXzAQnrl-Db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load weights\n",
        "transformer = Transformer(num_layers=num_layers, d_model=d_model, num_heads=num_heads,\n",
        "                          dff=dff, input_vocab_size=vocab_size, target_vocab_size=vocab_size,\n",
        "                          dropout_rate=dropout_rate)\n",
        "transformer.load_weights(model_checkpoint_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSQ2S3jfmQwU",
        "outputId": "ac235da3-63ce-4756-e020-611014db6e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7b63dacb4af0>"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Inference\n",
        "Create a model to generate comments from prompts:\n",
        "* Encode prompt with `tokenizer`, trim, add `[START],[END]`, then pad - this is the encoder input\n",
        "* calculate padding masks and look-ahead masks\n",
        "* `decoder` outputs preds by looking at `encoder` output and own output\n",
        "* Concatenate predicted token to decoder input and pass to of decoder\n",
        "* Decoder predicts next token based on previous tokens it predicted"
      ],
      "metadata": {
        "id": "6TLa8PsBtJDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Commentator(tf.Module):\n",
        "  def __init__(self, tokenizers, transformer):\n",
        "    self.tokenizers = tokenizers\n",
        "    self.transformer = transformer\n",
        "\n",
        "  def __call__(self, sentence, max_length=MAX_TOKENS):\n",
        "    # Add '[START]' and '[END]' tokens to input sentence\n",
        "    assert isinstance(sentence, tf.Tensor)\n",
        "    if len(sentence.shape) == 0:\n",
        "      sentence = sentence[tf.newaxis]\n",
        "\n",
        "    sentence = self.tokenizers.tokenize(sentence)[:,:MAX_TOKENS-2,:]\n",
        "    sentence = tf.squeeze(add_start_end(sentence).to_tensor(shape=(1,MAX_TOKENS,1)),axis=2)\n",
        "\n",
        "    encoder_input = sentence\n",
        "\n",
        "    # Init output with '[START]' token\n",
        "    out = self.tokenizers.tokenize(tf.constant(['']))\n",
        "    start_end = add_start_end(out)[0]\n",
        "    start = start_end[0][tf.newaxis]\n",
        "    end = start_end[1][tf.newaxis]\n",
        "\n",
        "    # 'tf.TensorArray' required so dynamic-loop traced by tf.function\n",
        "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
        "    output_array = output_array.write(0, start)\n",
        "\n",
        "    for i in tf.range(max_length):\n",
        "      output = tf.transpose(output_array.stack())\n",
        "      output = tf.reshape(output,(1,output.shape[2],1))\n",
        "      output = tf.concat([output, tf.zeros((1,MAX_TOKENS-output.shape[1],1),dtype='int64')], axis=1)\n",
        "      # print(output)\n",
        "      output = tf.squeeze(output, axis=2)\n",
        "      # print(output)\n",
        "      predictions = self.transformer([encoder_input, output], training = False)\n",
        "\n",
        "      # Select last token for `seq_len` dimension\n",
        "      predictions = predictions[:,-1:,:] # Shape `(batch_size, 1, vocab_size)`\n",
        "      print(predictions[:,:,:20])\n",
        "      predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "      # Concatenate `predicted_id` to output given to decoder as input\n",
        "      print(f'Token ID: {predicted_id}\\nToken: {tokenizer.detokenize(predicted_id)}')\n",
        "      output_array = output_array.write(i+1, predicted_id)\n",
        "\n",
        "      if predicted_id == end:\n",
        "        break\n",
        "\n",
        "    output = tf.squeeze(tf.transpose(output_array.stack()), axis=0)\n",
        "    # output shape `(1,tokens)`\n",
        "    text = tf.strings.reduce_join(self.tokenizers.detokenize(output)[0], axis=0, separator=\" \") # Shape: `()`\n",
        "\n",
        "    tokens = self.tokenizers.detokenize(output)[0]\n",
        "    print(f'Tokens: {tokens}')\n",
        "    # `tf.function` prevents usage of attention_wieghts calculated\n",
        "    # on last iteration of loop - recalc. outside of loop\n",
        "    self.transformer([encoder_input, output[:,:-1]], training=False)\n",
        "    attention_weights = self.transformer.decoder.last_attn_scores\n",
        "\n",
        "    return text, tokens, attention_weights"
      ],
      "metadata": {
        "id": "y8B1t1LcXr99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "commentator = Commentator(tokenizer, transformer)\n",
        "\n",
        "def print_comment(sentence, tokens):\n",
        "  print(f'{\"Input:\":15s}: {sentence}')\n",
        "  print(f'{\"Prediction\":15s}: {tokens.numpy().decode(\"utf-8\")}')\n",
        "\n",
        "sentence = 'I miss'\n",
        "output_text, output_tokens, attention_weights = commentator(tf.constant(sentence))\n",
        "print_comment(sentence, output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC4EQkL-SrXU",
        "outputId": "6ea1869c-bf62-4676-b2ce-0538db0ac18d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[-13.883633    -7.338079   -13.902933     3.5451252    2.908659\n",
            "    -0.09571538  -7.1459603   -5.9502454   -8.734787   -11.164272\n",
            "     0.7126359   -9.874228    -5.017789    -6.0291224  -11.039936\n",
            "     2.7767124   -4.7800946   -1.6145772   -7.7028856   -5.9787483 ]]], shape=(1, 1, 20), dtype=float32)\n",
            "Token ID: [[3]]\n",
            "Token: <tf.RaggedTensor [[b'[END]']]>\n",
            "Tokens: [b'[START]' b'[END]']\n",
            "Input:         : I miss\n",
            "Prediction     : [START] [END]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence2 = tf.constant('Take care of')\n",
        "out_text2, out_toks2, attn_wts2 = commentator(sentence2)\n",
        "print_comment(sentence2, out_text2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2nILynwl8Yi",
        "outputId": "255564aa-980d-4f20-ebf6-2daf0dfd5428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[-14.055527   -7.3926663 -14.074556    3.4394395   2.9511986\n",
            "    -0.3863879  -7.2340217  -5.9365435  -8.750813  -11.356359\n",
            "     0.6319177 -10.059809   -5.1890182  -6.3959117 -11.280291\n",
            "     2.7238004  -4.6797585  -1.5573555  -7.863919   -6.0857697]]], shape=(1, 1, 20), dtype=float32)\n",
            "Token ID: [[3]]\n",
            "Token: <tf.RaggedTensor [[b'[END]']]>\n",
            "Tokens: [b'[START]' b'[END]']\n",
            "Input:         : b'Take care of'\n",
            "Prediction     : [START] [END]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TemperatureCommentator(tf.Module):\n",
        "  def __init__(self, tokenizers, transformer):\n",
        "    self.tokenizers = tokenizers\n",
        "    self.transformer = transformer\n",
        "\n",
        "  def __call__(self, sentence, temperature = 0.1, max_length=MAX_TOKENS):\n",
        "    # Add '[START]' and '[END]' tokens to input sentence\n",
        "    assert isinstance(sentence, tf.Tensor)\n",
        "    if len(sentence.shape) == 0:\n",
        "      sentence = sentence[tf.newaxis]\n",
        "\n",
        "    sentence = self.tokenizers.tokenize(sentence)[:,:MAX_TOKENS-2,:]\n",
        "    sentence = tf.squeeze(add_start_end(sentence).to_tensor(shape=(1,MAX_TOKENS,1)),axis=2)\n",
        "    #sentence = add_start_end(sentence).to_tensor(shape=(1,MAX_TOKENS,1))\n",
        "\n",
        "    encoder_input = sentence\n",
        "\n",
        "    # Init output with '[START]' token\n",
        "    out = self.tokenizers.tokenize(tf.constant(['']))\n",
        "    start_end = add_start_end(out)[0]\n",
        "    start = start_end[0][tf.newaxis]\n",
        "    end = start_end[1][tf.newaxis]\n",
        "\n",
        "    # 'tf.TensorArray' required so dynamic-loop traced by tf.function\n",
        "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
        "    output_array = output_array.write(0, start)\n",
        "\n",
        "    for i in tf.range(max_length):\n",
        "      # output = tf.squeeze(tf.transpose(output_array.stack()), axis=0)\n",
        "      output = tf.transpose(output_array.stack())\n",
        "      output = tf.reshape(output,(1,output.shape[2],1))\n",
        "      output = tf.concat([output, tf.zeros((1,MAX_TOKENS-output.shape[1],1),dtype='int64')], axis=1)\n",
        "      output = tf.squeeze(output, axis=2)\n",
        "\n",
        "      predictions = self.transformer((encoder_input, output), training = False)\n",
        "\n",
        "\n",
        "      # Select last token for `seq_len` dimension\n",
        "      # print(predictions)\n",
        "      predictions = tf.squeeze(predictions[:,-1:,:]/temperature, axis=0) # Shape `(batch_size, 1, vocab_size)`\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)\n",
        "\n",
        "      # Concatenate `predicted_id` to output given to decoder as input\n",
        "      # print(f'Pred Token ID: {predicted_id}')\n",
        "      print(f'Pred Token: {tokenizer.detokenize(predicted_id)}')\n",
        "      output_array = output_array.write(i+1, predicted_id)\n",
        "\n",
        "      if predicted_id == end:\n",
        "        break\n",
        "\n",
        "    output = tf.squeeze(tf.transpose(output_array.stack()), axis=0)\n",
        "    # output shape `(1,tokens)`\n",
        "    text = tf.strings.reduce_join(self.tokenizers.detokenize(output)[0], axis=0, separator=\" \") # Shape: `()`\n",
        "\n",
        "    tokens = self.tokenizers.detokenize(output)[0]\n",
        "    # `tf.function` prevents usage of attention_wieghts calculated\n",
        "    # on last iteration of loop - recalc. outside of loop\n",
        "    self.transformer([encoder_input, output[:,:-1]], training=False)\n",
        "    attention_weights = self.transformer.decoder.last_attn_scores\n",
        "\n",
        "    return text, tokens, attention_weights"
      ],
      "metadata": {
        "id": "5Q8ijKofneN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_commentator = TemperatureCommentator(tokenizer, transformer)\n",
        "\n",
        "def print_comment(sentence, tokens):\n",
        "  print(f'{\"Input:\":15s}: {sentence}')\n",
        "  print(f'{\"Prediction\":15s}: {tokens.numpy().decode(\"utf-8\")}')\n",
        "\n",
        "sentence = 'I miss'\n",
        "output_text, output_tokens, attention_weights = temp_commentator(tf.constant(sentence),1.5)\n",
        "print_comment(sentence, output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaO0xZ4K9o8C",
        "outputId": "f739536d-136b-4385-a29d-a2d7a816d247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred Token: <tf.RaggedTensor [[b'skipped']]>\n",
            "Pred Token: <tf.RaggedTensor [[b'tricky']]>\n",
            "Pred Token: <tf.RaggedTensor [[b'?']]>\n",
            "Pred Token: <tf.RaggedTensor [[b'looking']]>\n",
            "Pred Token: <tf.RaggedTensor [[b'on']]>\n",
            "Pred Token: <tf.RaggedTensor [[b'catch']]>\n",
            "Pred Token: <tf.RaggedTensor [[b'are']]>\n",
            "Pred Token: <tf.RaggedTensor [[b'!']]>\n",
            "Pred Token: <tf.RaggedTensor [[b'was']]>\n",
            "Pred Token: <tf.RaggedTensor [[b'[END]']]>\n",
            "Input:         : I miss\n",
            "Prediction     : [START] skipped tricky ? looking on catch are ! was [END]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'Take care of'\n",
        "output_text, output_tokens, attention_weights = temp_commentator(tf.constant(sentence),1.5)\n",
        "print_comment(sentence, output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6YgSMyl30pE",
        "outputId": "282bd998-f01d-4666-d190-942e4c6c58e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred Token: <tf.RaggedTensor [[b'fauna']]>\n",
            "Pred Token: <tf.RaggedTensor [[b'!']]>\n",
            "Pred Token: <tf.RaggedTensor [[b'you']]>\n",
            "Pred Token: <tf.RaggedTensor [[b'you']]>\n",
            "Pred Token: <tf.RaggedTensor [[b'i']]>\n",
            "Pred Token: <tf.RaggedTensor [[b'glad']]>\n",
            "Pred Token: <tf.RaggedTensor [[b',']]>\n",
            "Pred Token: <tf.RaggedTensor [[b'what']]>\n",
            "Pred Token: <tf.RaggedTensor [[b'fauna']]>\n",
            "Pred Token: <tf.RaggedTensor [[b',']]>\n",
            "Pred Token: <tf.RaggedTensor [[b'quickly']]>\n",
            "Pred Token: <tf.RaggedTensor [[b'for']]>\n",
            "Pred Token: <tf.RaggedTensor [[b'[END]']]>\n",
            "Input:         : Take care of\n",
            "Prediction     : [START] fauna ! you you i glad , what fauna , quickly for [END]\n"
          ]
        }
      ]
    }
  ]
}