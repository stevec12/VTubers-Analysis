{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvt7nIerEK42Y3iAa/y26h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stevec12/VTubers-Analysis/blob/main/CommentPrompting2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comment Prompting\n",
        "This Jupyter notebook looks at training a basic transformer to provide responses to prompts based on how a YoutTuber's comments would likely reply.\n",
        "\n",
        "The YouTuber chosen is for the demo is [Ceres Fauna](!https://www.youtube.com/channel/UCO_aKKYxn4tvrqPjcTzZ6EQ), an English streamer with predominantly English comments.\n",
        "\n",
        "The channel ID is `UCO_aKKYxn4tvrqPjcTzZ6EQ`."
      ],
      "metadata": {
        "id": "R9P3PkBKBAqK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Extraction\n",
        "The `YouTube Data API v3` can be used for this task, and an account-linked API-key can be obtained using your personal Google (Developer) Account."
      ],
      "metadata": {
        "id": "nKHKEv3UCDd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import googleapiclient.discovery\n",
        "import googleapiclient.errors\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "!pip install xlsxwriter\n",
        "import xlsxwriter"
      ],
      "metadata": {
        "id": "zU9QbdDpRqeR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8458deb9-0d1a-49e0-f8c5-ce4e72748e3b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.1.9-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.1.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input API Key: \")\n",
        "api_key = input()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "633vu2o7P3Rs",
        "outputId": "ec005340-c894-4295-8b87-ac251db33fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input API Key: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VNtmD6yA9KH"
      },
      "outputs": [],
      "source": [
        "# Input target channel, example is @CeresFauna\n",
        "channelID = 'UCO_aKKYxn4tvrqPjcTzZ6EQ'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_service_name = \"youtube\"\n",
        "api_version = \"v3\"\n",
        "youtube = googleapiclient.discovery.build(api_service_name, api_version, developerKey=api_key)"
      ],
      "metadata": {
        "id": "bnUk47X1WPjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_uploadedID(channelID):\n",
        "  request = youtube.channels().list(\n",
        "      part=\"contentDetails\",\n",
        "      id=channelID\n",
        "    )\n",
        "  response = request.execute()\n",
        "\n",
        "  return response['items'][0]['contentDetails']['relatedPlaylists']['uploads']"
      ],
      "metadata": {
        "id": "jkoA1_GiWU09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploadedID=find_uploadedID(channelID)"
      ],
      "metadata": {
        "id": "7LkCawW_WcQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_uploaded(uploadedID):\n",
        "  videoIDs = []\n",
        "  request = youtube.playlistItems().list(\n",
        "        part=\"contentDetails\",\n",
        "        playlistId = uploadedID,\n",
        "        maxResults = 50\n",
        "  )\n",
        "  response = request.execute()\n",
        "  for item in response['items']:\n",
        "    videoIDs.append(item['contentDetails']['videoId'])\n",
        "  while('nextPageToken' in response):\n",
        "    request=youtube.playlistItems().list(\n",
        "        part='contentDetails',\n",
        "        playlistId=uploadedID,\n",
        "        pageToken=response['nextPageToken'],\n",
        "        maxResults=50)\n",
        "    response = request.execute()\n",
        "    for item in response['items']:\n",
        "      videoIDs.append(item['contentDetails']['videoId'])\n",
        "\n",
        "  return videoIDs"
      ],
      "metadata": {
        "id": "oefayJeWXusJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded=find_uploaded(uploadedID)"
      ],
      "metadata": {
        "id": "pwn7iZ7MXw_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_comments(videoID : str) -> pd.DataFrame:\n",
        "  '''\n",
        "  Given a videoID, return a pandas DataFrame with video info\n",
        "  '''\n",
        "  column_names = ['videoID','isTopLevel','topLevelID','commentID','authorDisplayName',\n",
        "                  'likeCount','publishedAt','totalReplyCount','textOriginal']\n",
        "\n",
        "  row_list = [] # Used to create list of dict of rows before conversion to dataframe, faster\n",
        "  pageToken=''\n",
        "  while(True):\n",
        "    request=youtube.commentThreads().list(\n",
        "        part=\"id,snippet,replies\",\n",
        "        videoId=videoID,\n",
        "        pageToken=pageToken,\n",
        "        maxResults=100\n",
        "    )\n",
        "    try:\n",
        "      response=request.execute()\n",
        "    except googleapiclient.errors.HttpError:\n",
        "      break\n",
        "\n",
        "    for commentThread in response['items']:\n",
        "      # write top level comment\n",
        "      topLevelID=commentThread['snippet']['topLevelComment']['id']\n",
        "      commentID=topLevelID\n",
        "      authorDisplayName=commentThread['snippet']['topLevelComment']['snippet']['authorDisplayName']\n",
        "      likeCount=commentThread['snippet']['topLevelComment']['snippet']['likeCount']\n",
        "      publishedAt=commentThread['snippet']['topLevelComment']['snippet']['publishedAt']\n",
        "      totalReplyCount=commentThread['snippet']['totalReplyCount']\n",
        "      textOriginal=commentThread['snippet']['topLevelComment']['snippet']['textOriginal']\n",
        "\n",
        "      row_list.append({'videoID':videoID,'isTopLevel':True,'topLevelID':topLevelID,\n",
        "                      'commentID':commentID,'authorDisplayName':authorDisplayName,\n",
        "                      'likeCount':likeCount,'publishedAt':publishedAt,\n",
        "                      'totalReplyCount':totalReplyCount,'textOriginal':textOriginal})\n",
        "\n",
        "      # If any replies, write them as well\n",
        "      if 'replies' in commentThread:\n",
        "        for reply in commentThread['replies']['comments']:\n",
        "          commentID=reply['id']\n",
        "          authorDisplayName=reply['snippet']['authorDisplayName']\n",
        "          likeCount=reply['snippet']['likeCount']\n",
        "          publishedAt=reply['snippet']['publishedAt']\n",
        "          textOriginal=reply['snippet']['textOriginal']\n",
        "\n",
        "          row_list.append({'videoID':videoID,'isTopLevel':False,'topLevelID':topLevelID,\n",
        "                           'commentID':commentID,'authorDisplayName':authorDisplayName,\n",
        "                           'likeCount':likeCount,'publishedAt':publishedAt,\n",
        "                           'totalReplyCount':totalReplyCount,'textOriginal':textOriginal})\n",
        "\n",
        "    if 'nextPageToken' not in response:\n",
        "      break\n",
        "    else:\n",
        "      pageToken=response['nextPageToken']\n",
        "\n",
        "  return pd.DataFrame(row_list, columns=column_names)\n"
      ],
      "metadata": {
        "id": "msEQBZdbYkRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def uploaded_comments_to_excel(file_name, uploaded = uploaded):\n",
        "  '''\n",
        "  Writes all comments in the Uploaded playlist to an excel file, as a single\n",
        "  worksheet.\n",
        "  '''\n",
        "  column_names = ['videoID','isTopLevel','topLevelID','commentID','authorDisplayName',\n",
        "                  'likeCount','publishedAt','totalReplyCount','textOriginal']\n",
        "  comment_df = get_video_comments(uploaded[0])\n",
        "\n",
        "  for videoID in uploaded[1:]:\n",
        "    comment_df = pd.concat([comment_df, get_video_comments(videoID)])\n",
        "\n",
        "  comment_df.to_excel(file_name, engine='xlsxwriter', index=False)\n"
      ],
      "metadata": {
        "id": "ZSJKXRcXsCWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded_comments_to_excel('ceres_fauna_comments_10_27_2023.xlsx')"
      ],
      "metadata": {
        "id": "ccL9tBPR1sE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the Data\n",
        "Preparing the data using TensorFlow preprocessing layers.\n",
        "\n",
        "Here, we use the `ceres_fauna_comments_10_27_2023.xlsx` excel file generated earlier."
      ],
      "metadata": {
        "id": "I6_e9cNGbCCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "!pip install tensorflow_text\n",
        "import tensorflow_text as text\n",
        "from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC6gkYsRbBvh",
        "outputId": "cadc2871-67a8-44ae-ec0c-87deaea15a0c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (0.15.0)\n",
            "Requirement already satisfied: tensorflow<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (2.14.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (1.59.2)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.15,>=2.14.0->tensorflow_text) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.15,>=2.14.0->tensorflow_text) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow<2.15,>=2.14.0->tensorflow_text) (3.2.2)\n",
            "Installing collected packages: tensorflow_text\n",
            "Successfully installed tensorflow_text-2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data into a pandas DataFrame\n",
        "comments_df = pd.read_excel('ceres_fauna_comments_10_27_2023.xlsx')"
      ],
      "metadata": {
        "id": "MKNeeBITas9V"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We filter out comments that are not at least two seperate words\n",
        "multiple_word_indices = np.char.find(comments_df['textOriginal'].to_numpy(dtype='str'), \" \") > -1\n",
        "multiple_word_series = comments_df.copy().loc[multiple_word_indices]['textOriginal']\n",
        "\n",
        "comments_tensor = tf.convert_to_tensor(multiple_word_series.to_numpy(dtype='str'), dtype='string')"
      ],
      "metadata": {
        "id": "qtITGgm8QC-P"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split the data into train, validation, and test splits.\n",
        "\n",
        "For reasonable training times, we use a 50/10/40 split."
      ],
      "metadata": {
        "id": "gc35nzFoh27I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comment_ds = tf.data.Dataset.from_tensor_slices(comments_tensor).shuffle(1000, seed=12)\n",
        "\n",
        "train_split = int(np.floor(0.5*len(comment_ds)))\n",
        "val_split = int(np.floor(0.1*len(comment_ds)))\n",
        "test_split = int(len(comment_ds) - train_split - val_split)\n",
        "\n",
        "train_ds = comment_ds.take(train_split)\n",
        "val_ds = comment_ds.skip(train_split).take(val_split)\n",
        "test_ds = comment_ds.skip(train_split + val_split).take(test_split)"
      ],
      "metadata": {
        "id": "hQZ9PIJRcDRJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate vocabulary using [subword tokenizers](https://www.tensorflow.org/text/guide/subwords_tokenizer) tutorial."
      ],
      "metadata": {
        "id": "JvT9hq5SfjSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tokenizer_params=dict(lower_case=True)\n",
        "reserved_tokens=[\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n",
        "\n",
        "bert_vocab_args = dict(\n",
        "    # The target vocabulary size\n",
        "    vocab_size = 8000,\n",
        "    # Reserved tokens that must be included in the vocabulary\n",
        "    reserved_tokens=reserved_tokens,\n",
        "    # Arguments for `text.BertTokenizer`\n",
        "    bert_tokenizer_params=bert_tokenizer_params,\n",
        "    # Arguments for `wordpiece_vocab.wordpiece_tokenizer_learner_lib.learn`\n",
        "    learn_params={},\n",
        ")"
      ],
      "metadata": {
        "id": "r6VcV382kgH1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_file = 'vocab2.txt'"
      ],
      "metadata": {
        "id": "UHHDzYZpyWs-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "vocab = bert_vocab.bert_vocab_from_dataset(\n",
        "    train_ds.batch(1000).prefetch(2),\n",
        "    **bert_vocab_args\n",
        ")\n",
        "\n",
        "# Save vocab to file\n",
        "\n",
        "with open(vocab_file, 'w') as f:\n",
        "  for token in vocab:\n",
        "    print(token, file=f)"
      ],
      "metadata": {
        "id": "lMFV_8B6gBSZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1097c34e-14fa-4ede-eccf-cdd886502f24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 12s, sys: 256 ms, total: 1min 12s\n",
            "Wall time: 1min 13s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 0\n",
        "with open(vocab_file, \"rb\") as f:\n",
        "    vocab_size = sum(1 for _ in f)"
      ],
      "metadata": {
        "id": "D7B3Qx6-xshl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize, trim (to `MAX_TOKENS`), and pad the inputs, as well as form into (input, label) Datasets where the label is the input right-shifted by one token.\n",
        "\n",
        "Then batch (batch size = `BATCH_SIZE`) and prefetch data."
      ],
      "metadata": {
        "id": "QshfKIgWC-k9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = text.BertTokenizer(vocab_file, **bert_tokenizer_params)"
      ],
      "metadata": {
        "id": "lWW4j7rpud-8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_TOKENS = 128\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "Y8sIifsFVN2C"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "START = tf.argmax(tf.constant(reserved_tokens) == \"[START]\")\n",
        "END = tf.argmax(tf.constant(reserved_tokens) == \"[END]\")\n",
        "\n",
        "def add_start_end(ragged):\n",
        "  count = ragged.bounding_shape()[0]\n",
        "  starts = tf.fill([count,1,1], START)\n",
        "  ends = tf.fill([count,1,1], END)\n",
        "\n",
        "  return tf.concat([starts, ragged, ends], axis=1)"
      ],
      "metadata": {
        "id": "DmoG18ibUxC0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to train the model to predict comments from given prompts. We have some options to do this:\n",
        "* Take the first half of the tokens as input, right-shift for the teacher, and take the re"
      ],
      "metadata": {
        "id": "DKAYo0ci-ngN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_batch(input_batch : tf.Tensor, batch_size = BATCH_SIZE, max_tokens=MAX_TOKENS):\n",
        "  '''\n",
        "  Take tensor with (sentence) and split into ((prompt,teacher),label) for training.\n",
        "  Firstly tokenized and trimmed, (sentence) is then split up to a random point k. Then:\n",
        "  prompt = [START] + sentence[0:k] + [END]\n",
        "  label = sentence + [END]\n",
        "  teacher = [START] + sentence\n",
        "  Finally, pad outputs to MAX_TOKENS length.\n",
        "  '''\n",
        "  # Tokenize\n",
        "  tokens = tokenizer.tokenize(input_batch)[:,:max_tokens-1,:]\n",
        "\n",
        "  # Create Prompts\n",
        "  prompt_tokens = tokens[:,:-1,:]\n",
        "  # Select a prompt length\n",
        "  token_lens = tf.cast(prompt_tokens.row_lengths()-1, dtype='float32') # Keep at least 1 token outside the prompt\n",
        "  #print(token_lens)\n",
        "  prompt_lens = tf.floor(tf.random.uniform([batch_size], tf.zeros_like(token_lens), token_lens))\n",
        "  #print(prompt_lens)\n",
        "  prompt_lens = tf.squeeze(tf.cast(prompt_lens,dtype='int32'))\n",
        "  # Form prompts of varied length\n",
        "  prompt = tf.squeeze(prompt_tokens.to_tensor(shape=(batch_size,max_tokens-2,1)), axis=2)\n",
        "  #print(prompt)\n",
        "  #print(prompt_lens)\n",
        "  prompt = tf.RaggedTensor.from_tensor(prompt,prompt_lens)[:,:,tf.newaxis]\n",
        "\n",
        "  # Tokenize\n",
        "  prompt = add_start_end(prompt)\n",
        "  teacher = add_start_end(tokens)[:,:-1,:]\n",
        "  label = add_start_end(tokens)[:,1:,:]\n",
        "\n",
        "  # 0-Pad  convert to dense tensor, then form shape (batch_size, max_tokens)\n",
        "  prompt = tf.squeeze(prompt.to_tensor(shape=(batch_size,max_tokens,1)))\n",
        "  teacher = tf.squeeze(teacher.to_tensor(shape=(batch_size,max_tokens,1)))\n",
        "  label = tf.squeeze(label.to_tensor(shape=(batch_size,max_tokens,1)))\n",
        "\n",
        "  # form Dataset\n",
        "  output_batch = ((prompt,teacher), label)\n",
        "\n",
        "  return output_batch"
      ],
      "metadata": {
        "id": "pxt3NRlYz6A5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop Remainder required for tf.random.uniform\n",
        "def make_batches(ds):\n",
        "  return (\n",
        "      ds\n",
        "      .batch(BATCH_SIZE, drop_remainder=True)\n",
        "      .map(prepare_batch, tf.data.AUTOTUNE)\n",
        "      .prefetch(buffer_size=tf.data.AUTOTUNE))"
      ],
      "metadata": {
        "id": "e4alFxA31AbR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_batches = make_batches(train_ds)\n",
        "val_batches = make_batches(val_ds)"
      ],
      "metadata": {
        "id": "9zj0rkrc3CHf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a singular batch as an example."
      ],
      "metadata": {
        "id": "JY7eV-WH5Jjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for (input,teacher), label in train_batches.take(1):\n",
        "  print(input.shape)\n",
        "  print(teacher.shape)\n",
        "  print(label.shape)"
      ],
      "metadata": {
        "id": "--IoHCaM4CfN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f998db97-ffe8-4a7d-a03e-dc356955f651"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 128)\n",
            "(64, 128)\n",
            "(64, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(input[0])\n",
        "print(teacher[0])\n",
        "print(label[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LteMAF345NfI",
        "outputId": "1d8cb912-553a-4017-926d-04a5ae6bbbcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[   2 1054 1063 1182 1045 1048 1349 1780    3    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0], shape=(128,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[   2 1054 1063 1182 1045 1048 1349 1780 1057  988  998 1288  993 1574\n",
            " 1131  986 1793  985 2492  992   53    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0], shape=(128,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[1054 1063 1182 1045 1048 1349 1780 1057  988  998 1288  993 1574 1131\n",
            "  986 1793  985 2492  992   53    3    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0], shape=(128,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert tokens to vectors with a `tf.keras.layers.Embedding` layer and add positional encoding."
      ],
      "metadata": {
        "id": "hYz1JD16eWZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(length, depth):\n",
        "  depth = depth/2\n",
        "\n",
        "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
        "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
        "\n",
        "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
        "  angle_rads = positions * angle_rates      # (pos, depth)\n",
        "\n",
        "  pos_encoding = np.concatenate(\n",
        "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
        "      axis=-1)\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "wJyTvASxeVO-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "  def __init__(self, vocab_size, d_model):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
        "    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
        "\n",
        "  def compute_mask(self, *args, **kwargs):\n",
        "    return self.embedding.compute_mask(*args, **kwargs)\n",
        "\n",
        "  def call(self, x):\n",
        "    length = tf.shape(x)[1]\n",
        "    x = self.embedding(x)\n",
        "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
        "    return x"
      ],
      "metadata": {
        "id": "octsiexdfjQx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed = PositionalEmbedding(vocab_size=vocab_size, d_model=512)\n",
        "te_emb = embed(teacher)\n",
        "te_emb._keras_mask;\n",
        "in_emb = embed(input)\n",
        "in_emb._keras_mask;"
      ],
      "metadata": {
        "id": "BufCEm_9gKYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()"
      ],
      "metadata": {
        "id": "8Qk7KH4D5XQg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossAttention(BaseAttention):\n",
        "  '''def __init__(self, **kwargs):\n",
        "    print('Initializing CrossAttention')\n",
        "    super().__init__(self, **kwargs)'''\n",
        "\n",
        "  def call(self, x, context):\n",
        "    attn_output, attn_scores = self.mha(\n",
        "        query = x,\n",
        "        key = context,\n",
        "        value = context,\n",
        "        return_attention_scores = True\n",
        "    )\n",
        "    # Cache the attention scores for plotting later.\n",
        "    self.last_attn_scores = attn_scores\n",
        "\n",
        "    x = self.add([x,attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "7aSUK3LaafK8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_ca = CrossAttention(num_heads=2, key_dim=512)\n",
        "print(in_emb.shape)\n",
        "print(sample_ca(in_emb, te_emb).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZP163reubafg",
        "outputId": "a410075b-7cb2-4801-9394-47c121b14e0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 128, 512)\n",
            "(64, 128, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GlobalSelfAttention(BaseAttention):\n",
        "  def call(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query = x,\n",
        "        key = x,\n",
        "        value = x\n",
        "    )\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "WAJfmyXYFd1z"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_gsa = GlobalSelfAttention(num_heads=2, key_dim=512)\n",
        "print(in_emb.shape)\n",
        "print(sample_gsa(in_emb).shape)"
      ],
      "metadata": {
        "id": "tArDk3HGCEEr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4d4bc6a-9d29-46ac-a9bf-c931afce1c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 128, 512)\n",
            "(64, 128, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalSelfAttention(BaseAttention):\n",
        "  def call(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query = x,\n",
        "        key = x,\n",
        "        value = x,\n",
        "        use_causal_mask = True\n",
        "    )\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "09Pw5iY0CT5h"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_csa = CausalSelfAttention(num_heads=2, key_dim=512)\n",
        "print(te_emb.shape)\n",
        "print(sample_csa(te_emb).shape)"
      ],
      "metadata": {
        "id": "n0QspLB2Enrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc8ec638-670e-499d-e077-c4fe3d2bb75d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 128, 512)\n",
            "(64, 128, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.seq = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(dff, activation='relu'),\n",
        "        tf.keras.layers.Dense(d_model),\n",
        "        tf.keras.layers.Dropout(dropout_rate)\n",
        "    ])\n",
        "    self.add = tf.keras.layers.Add()\n",
        "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.add([x,self.seq(x)])\n",
        "    x = self.layer_norm(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "ubYe9mNEFUGo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_ffn = FeedForward(512,2048)\n",
        "\n",
        "print(te_emb.shape)\n",
        "print(sample_ffn(te_emb).shape)"
      ],
      "metadata": {
        "id": "eDIjRizeM5x-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f9621f2-db68-4d84-d3cb-2bcabd47a7d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 128, 512)\n",
            "(64, 128, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,*,d_model,num_heads,dff,dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.self_attention = GlobalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate\n",
        "    )\n",
        "    self.ffn = FeedForward(d_model,dff)\n",
        "\n",
        "  def call(self,x):\n",
        "    x = self.self_attention(x)\n",
        "    x = self.ffn(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "qn8SHOyGNFgk"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_encoder_layer = EncoderLayer(d_model=512, num_heads=8,dff=2048)\n",
        "print(in_emb.shape)\n",
        "print(sample_encoder_layer(in_emb).shape)"
      ],
      "metadata": {
        "id": "avMB0tQCPgT7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cef3b5e-6a21-48f0-b131-1b33544a6de9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 128, 512)\n",
            "(64, 128, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(\n",
        "        vocab_size = vocab_size, d_model = d_model\n",
        "    )\n",
        "\n",
        "    self.enc_layers = [\n",
        "        EncoderLayer(d_model=d_model,\n",
        "                     num_heads=num_heads,\n",
        "                     dff=dff,\n",
        "                     dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)\n",
        "    ]\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self,x):\n",
        "    # `x` is token-IDs shape: (batch_size, seq_len)\n",
        "    x = self.pos_embedding(x) # Shape '(batch_size, seq_len, d_model)'.\n",
        "\n",
        "    # Add dropout\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x)\n",
        "\n",
        "    return x # Shape `(batch_size, seq_length, d_model)`"
      ],
      "metadata": {
        "id": "mjYtpLjSQOvz"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test encoder\n",
        "sample_encoder = Encoder(num_layers=4, d_model=512, num_heads=8, dff=2048, vocab_size=vocab_size)\n",
        "sample_encoder_output = sample_encoder(input,training=False)\n",
        "\n",
        "print(in_emb.shape)\n",
        "print(sample_encoder_output.shape) # Shape `(batch_size, input_seq_len, d_model)`"
      ],
      "metadata": {
        "id": "_VPjyUQvU2Ta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2087a0bd-af65-4901-d642-586b6c30666b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 128, 512)\n",
            "(64, 128, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,*,d_model,num_heads,dff,dropout_rate=0.1):\n",
        "    super(DecoderLayer,self).__init__()\n",
        "\n",
        "    self.causal_self_attention = CausalSelfAttention(\n",
        "        num_heads = num_heads,\n",
        "        key_dim = d_model,\n",
        "        dropout = dropout_rate\n",
        "    )\n",
        "\n",
        "    self.cross_attention = CrossAttention(\n",
        "        num_heads = num_heads,\n",
        "        key_dim = d_model,\n",
        "        dropout = dropout_rate\n",
        "    )\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x, context):\n",
        "    x = self.causal_self_attention(x=x)\n",
        "    x = self.cross_attention(x=x, context=context)\n",
        "\n",
        "    # Cache last attention scores for plotting later\n",
        "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
        "\n",
        "    x = self.ffn(x) # Shape `(batch_size, seq_len, d_model)`\n",
        "    return x"
      ],
      "metadata": {
        "id": "WAaVdSSAU2NA"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_decoder_layer = DecoderLayer(d_model=512, num_heads=8, dff=2048)\n",
        "\n",
        "sample_decoder_layer_output = sample_decoder_layer(x=te_emb, context=in_emb)\n",
        "\n",
        "print(te_emb.shape)\n",
        "print(in_emb.shape)\n",
        "print(sample_decoder_layer_output.shape) # `(batch_size, seq_len, d_model)`"
      ],
      "metadata": {
        "id": "dWrc5yzTYmjm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ffd68b7-a3b8-4d94-90b7-887d94a3f709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 128, 512)\n",
            "(64, 128, 512)\n",
            "(64, 128, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self,*,num_layers, d_model, num_heads, dff, vocab_size, dropout_rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size, d_model=d_model)\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "    self.dec_layers = [\n",
        "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
        "                     dff=dff, dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)\n",
        "    ]\n",
        "    self.last_attn_scores = None\n",
        "\n",
        "  def call(self, x, context):\n",
        "    # `x` is token-IDs shape (batch, target_seq_len)\n",
        "    x = self.pos_embedding(x) # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.dec_layers[i](x,context)\n",
        "\n",
        "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
        "\n",
        "    # shape of x is (batch_size, target_seq_len, d_model)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "9SnFsXHNM7MA"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_decoder = Decoder(num_layers=4, d_model=512, num_heads=8,\n",
        "                         dff=2048, vocab_size=vocab_size)\n",
        "\n",
        "output = sample_decoder(x=teacher, context=in_emb)\n",
        "\n",
        "print(teacher.shape)\n",
        "print(in_emb.shape)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEugWQp3fimJ",
        "outputId": "19962b4a-c390-41e3-f257-362761e60ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 128)\n",
            "(64, 128, 512)\n",
            "(64, 128, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_decoder.last_attn_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3syvsrVgFKL",
        "outputId": "70d328dd-50d2-4f2a-d734-3e3dffbe9604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 8, 128, 128), dtype=float32, numpy=\n",
              "array([[[[0.11104868, 0.11142529, 0.11069106, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.11103439, 0.11104572, 0.11088928, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.11159551, 0.11177482, 0.11118655, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.11113437, 0.11103407, 0.11085951, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.11089264, 0.11112651, 0.11106726, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.1107775 , 0.1106852 , 0.11086118, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.11110605, 0.11143898, 0.11127587, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.11074343, 0.11164052, 0.11062901, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.11096189, 0.11147898, 0.11080518, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.1108829 , 0.11162161, 0.11168624, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.11091309, 0.11164146, 0.11110453, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.11136728, 0.11115897, 0.11101787, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.11084149, 0.11118863, 0.11092524, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.11072853, 0.11187522, 0.11087116, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.11070398, 0.11149077, 0.1111424 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.11145088, 0.11070115, 0.11093254, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.11107954, 0.1109118 , 0.11084083, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.11135574, 0.11119733, 0.11067495, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]]],\n",
              "\n",
              "\n",
              "       [[[0.33307922, 0.33348218, 0.33343863, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.3338762 , 0.33374918, 0.33237454, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.33357665, 0.33353359, 0.33288974, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.332958  , 0.33293304, 0.3341089 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.33356115, 0.33257538, 0.33386335, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.33434895, 0.3334797 , 0.33217132, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.33314663, 0.33314553, 0.3337078 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.33218297, 0.33280993, 0.33500707, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.33339712, 0.33291572, 0.33368716, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.33315974, 0.33324853, 0.33359185, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.33373454, 0.33378088, 0.33248454, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.33437777, 0.33389693, 0.33172533, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.33368912, 0.33385578, 0.33245498, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.33414453, 0.33303684, 0.33281866, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.3330808 , 0.33354038, 0.3333788 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.33396974, 0.33393112, 0.3320991 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.3338612 , 0.33289152, 0.33324736, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.33381662, 0.33339006, 0.3327933 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]]],\n",
              "\n",
              "\n",
              "       [[[0.12496051, 0.12502295, 0.12497202, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.1250899 , 0.12485857, 0.12477952, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.12539908, 0.12460408, 0.1246122 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.12495167, 0.12471449, 0.12497008, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.12509678, 0.12423734, 0.12485287, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.12481277, 0.12485939, 0.1251734 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.12485828, 0.12538913, 0.12513854, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.12456765, 0.1247439 , 0.12500097, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.12508033, 0.12433256, 0.12459619, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.12476556, 0.1249489 , 0.12504426, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.1248327 , 0.12543301, 0.1250751 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.12527217, 0.12510642, 0.1248926 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.12477255, 0.12559421, 0.12517637, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.1248325 , 0.12521814, 0.1254698 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.12451279, 0.12544538, 0.12582871, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.12547927, 0.1251505 , 0.12540326, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.12484079, 0.12481276, 0.12546726, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.12550668, 0.12510103, 0.12543008, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.00900763, 0.0090161 , 0.00901294, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.00903346, 0.00904457, 0.00903508, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.00901176, 0.00898982, 0.00897447, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.00901255, 0.00899944, 0.00898876, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.00901252, 0.00899046, 0.00898721, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.0090136 , 0.00898462, 0.0089866 , ..., 0.        ,\n",
              "          0.        , 0.        ]],\n",
              "\n",
              "        [[0.00901345, 0.00898176, 0.00897748, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.00903982, 0.00897339, 0.00900423, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.00904872, 0.0090073 , 0.00901307, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0090272 , 0.00900352, 0.00898841, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.00902996, 0.00900864, 0.00898733, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.00903156, 0.00901481, 0.00898927, ..., 0.        ,\n",
              "          0.        , 0.        ]],\n",
              "\n",
              "        [[0.00898629, 0.00898774, 0.00901558, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.00895526, 0.00897122, 0.00894933, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.00901138, 0.00899645, 0.00898106, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.00901053, 0.00899962, 0.00899243, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.00900888, 0.0089919 , 0.00898559, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.00901036, 0.00898668, 0.00898134, ..., 0.        ,\n",
              "          0.        , 0.        ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.00897149, 0.00902585, 0.00902253, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.00898291, 0.00898975, 0.00896915, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.00897104, 0.00900476, 0.0089836 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.00896024, 0.00898209, 0.00901591, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.00896298, 0.00898103, 0.00901875, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.0089718 , 0.0089851 , 0.00902498, ..., 0.        ,\n",
              "          0.        , 0.        ]],\n",
              "\n",
              "        [[0.00898013, 0.00898129, 0.00900377, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.00901064, 0.00905832, 0.00906057, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.00898381, 0.00898388, 0.00895411, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.00899062, 0.00903532, 0.00897583, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.00899018, 0.009042  , 0.00897625, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.0089895 , 0.00904662, 0.00898001, ..., 0.        ,\n",
              "          0.        , 0.        ]],\n",
              "\n",
              "        [[0.00905832, 0.00904525, 0.0090306 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.00904922, 0.00900639, 0.00902797, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.00905345, 0.00902918, 0.00902156, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0090382 , 0.00903149, 0.00902629, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.00904173, 0.00903638, 0.00903263, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.00903934, 0.00903978, 0.00903377, ..., 0.        ,\n",
              "          0.        , 0.        ]]],\n",
              "\n",
              "\n",
              "       [[[0.08332261, 0.08356137, 0.08368056, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.08372306, 0.08351869, 0.08345339, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.08345842, 0.08336072, 0.08314733, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.08347912, 0.08373887, 0.0828943 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.08339405, 0.08373264, 0.08322195, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.08357456, 0.08335276, 0.08320457, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.08331754, 0.08355864, 0.0835041 , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.08345234, 0.08306196, 0.08330321, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.08355016, 0.08341227, 0.08302679, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.0831739 , 0.08333471, 0.08326127, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.08359027, 0.0835404 , 0.08363803, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.08334793, 0.0834054 , 0.08331598, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.08312642, 0.0831746 , 0.08320379, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.0830875 , 0.08294441, 0.08321871, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.08289601, 0.08316407, 0.08356553, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.08357166, 0.08340549, 0.08347171, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.0832133 , 0.08338834, 0.08339934, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.08346492, 0.08339895, 0.08348335, ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]]],\n",
              "\n",
              "\n",
              "       [[[0.49940974, 0.5005903 , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.5003352 , 0.4996648 , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.5002595 , 0.49974042, 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.49917015, 0.5008298 , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.49992016, 0.5000799 , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.49986234, 0.50013757, 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.49949294, 0.500507  , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.4991967 , 0.5008033 , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.5008361 , 0.4991639 , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.49960592, 0.5003939 , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.5009558 , 0.49904412, 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.5010552 , 0.49894482, 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.50096714, 0.4990329 , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.5002985 , 0.49970147, 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.5011208 , 0.4988792 , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]],\n",
              "\n",
              "        [[0.5014339 , 0.498566  , 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.5017817 , 0.49821824, 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         [0.50046885, 0.49953118, 0.        , ..., 0.        ,\n",
              "          0.        , 0.        ],\n",
              "         ...,\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ],\n",
              "         [0.0078125 , 0.0078125 , 0.0078125 , ..., 0.0078125 ,\n",
              "          0.0078125 , 0.0078125 ]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
        "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model, num_heads=num_heads,\n",
        "                           dff=dff, vocab_size=input_vocab_size, dropout_rate=dropout_rate)\n",
        "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model, num_heads=num_heads,\n",
        "                           dff=dff, vocab_size=target_vocab_size, dropout_rate=dropout_rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # To support Keras model '.fit', pass all inputs as first argument\n",
        "    context, x = inputs\n",
        "\n",
        "    context = self.encoder(context) # (batch_size, context_len, d_model)\n",
        "\n",
        "    x = self.decoder(x, context) # (batch_size, target_len, d_model)\n",
        "\n",
        "    logits = self.final_layer(x) # (batch_size, target_len, target_vocab_size)\n",
        "\n",
        "    try:\n",
        "      # Drop keras mask, so it doesn't scale losses/metrics\n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    # Return final output and attention weights\n",
        "    return logits"
      ],
      "metadata": {
        "id": "cJ54y09FgegC"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters"
      ],
      "metadata": {
        "id": "DsECFvcbiyEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1"
      ],
      "metadata": {
        "id": "vtN0P31SiuF_"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "MUoyRRlXjAOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = Transformer(num_layers=num_layers, d_model=d_model, num_heads=num_heads,\n",
        "                          dff=dff, input_vocab_size=vocab_size, target_vocab_size=vocab_size,\n",
        "                          dropout_rate=dropout_rate)"
      ],
      "metadata": {
        "id": "rvLmL2v9i81z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = transformer((input,teacher))\n",
        "print(teacher.shape)\n",
        "print(input.shape)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKuqmIkDjVur",
        "outputId": "69bb27a9-5472-438f-96f6-d575c56f1ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 128)\n",
            "(64, 128)\n",
            "(64, 128, 7986)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = transformer.decoder.dec_layers[-1].last_attn_scores\n",
        "print(attn_scores.shape) # batch, heads, target_seq, input_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5P2mBGmvTvX",
        "outputId": "54677bec-c22b-4af1-d7cf-80a41ccf0550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 4, 128, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JwM1rpYwAFo",
        "outputId": "75ffbe01-6f55-497a-a7ab-8ed6080d3127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder (Encoder)           multiple                  3661056   \n",
            "                                                                 \n",
            " decoder (Decoder)           multiple                  5772032   \n",
            "                                                                 \n",
            " dense_16 (Dense)            multiple                  1030194   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10463282 (39.91 MB)\n",
            "Trainable params: 10463282 (39.91 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_token_vector = tf.argmax(output,axis=2)\n",
        "pred_token = tokenizer.detokenize(pred_token_vector)\n",
        "pred_phrases = tf.strings.reduce_join(pred_token,axis=1,separator=' ')\n",
        "print(pred_phrases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNxfYwexwCeO",
        "outputId": "7305ac03-ce6d-4d22-f271-3a7564345d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'cave $ \\xe9\\x80\\xb2 destroying progress alert route destroying aw hadn woman woman laying pocket rat caring rat rat\\xf0\\x9f\\xa5\\xb4 weak \\xf0\\x9f\\x98\\x89 duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'cave destroying destroying destroying \\xf0\\x9f\\x8e\\xb7ball\\xf0\\x9f\\xa7\\xa2 angry counter\\xe7\\xb4\\xb0shedshed pocket pocket finds finds first raw raw raw comment duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly pumpkingsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9cballballball \\xe5\\xbf\\x9c disappoint disappoint \\xe3\\x82\\xabballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c bucket bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity \\xf0\\x9f\\xa4\\x8e\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2 spectacularza destroying progress route\\xf0\\x9f\\xa7\\xa2 route premium\\xe7\\xb4\\xb0 impressions impressions progress progress finds caring21 rat\\xf0\\x9f\\xa5\\xb4 roleplay destroying \\xf0\\x9f\\x98\\x89 noticed noticed \\xf0\\x9f\\x98\\x90\\xf0\\x9f\\xa5\\xb4 \\xe8\\xa6\\xb3 \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2\\xf0\\x9f\\xa7\\xa2 \\xf0\\x9f\\x8e\\xb7ball progressball route alert \\xf0\\x9f\\x98\\x89 impressions impressions impressions improving pocket progress caring rat rat rat\\xf0\\x9f\\xa5\\xb4 \\xf0\\x9f\\x98\\x89 duo \\xf0\\x9f\\x98\\x89 ultimate joined exquisite\\xf0\\x9f\\xa5\\xb4 anymore\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 poll\\xc9\\xaa\\xe7\\x89\\xa9 follow mods\\xe7\\x89\\xa9 finale \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2 destroying \\xe9\\x80\\xb2 destroying alert routeza\\xe1\\x85\\xa1 particularly hadn noticed impressions\\xc9\\xaa \\xf0\\x9f\\x98\\xa2 pocket21 rat rat just comment duo duo noticed noticed describe\\xf0\\x9f\\xa5\\xb4 \\xe8\\xa6\\xb3 \\xe8\\xa6\\xb3 \\xe8\\xa6\\xb3ball replaceball follow follow first finale finale \\xe5\\xbf\\x9c 0pseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygs v \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner dinner\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'cave destroying destroying destroyingballballball counter counter\\xe7\\xb4\\xb0shedshed pocket pocket finds finds first raw raw raw comment duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly pumpkingsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9cballballball \\xe5\\xbf\\x9c disappoint disappoint \\xe3\\x82\\xabballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c bucket bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity \\xf0\\x9f\\xa4\\x8e\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2 mean destroying destroying progressball alert\\xf0\\x9f\\xa7\\xa2 hadn blow woman hard pocket pocket caring duo rat caring hide describe \\xf0\\x9f\\x98\\x89 \\xf0\\x9f\\x98\\x89 comment \\xe3\\x81\\xa3ball \\xf0\\x9f\\x98\\x90\\xf0\\x9f\\xa5\\xb4 \\xe8\\xa6\\xb3ball\\xf0\\x9f\\xa5\\xb4 running lists follow follow running finale finale begins \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner dinner\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'cave destroying destroying destroyingzaza draw counter counter\\xe7\\xb4\\xb0shedshed pocket pocket finds finds first raw raw raw comment duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly pumpkingsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9cballballball \\xe5\\xbf\\x9c disappoint disappoint \\xe3\\x82\\xabballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c bucket bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity \\xf0\\x9f\\xa4\\x8e\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2 woah dull wondering \\xf0\\x9f\\x8e\\xb7\\xf0\\x9f\\xa7\\xa2 route route premium hadn rat improving improving progress finds rat rat rat\\xe5\\xbc\\x95 raw \\xf0\\x9f\\x98\\x89 duo core \\xf0\\x9f\\x98\\x89 \\xf0\\x9f\\x98\\x90 episodes \\xe8\\xa6\\xb3 \\xe8\\xa6\\xb3 finale\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner dinner\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2 destroying destroying impressionsball\\xf0\\x9f\\xa7\\xa2 alert alert agreed impressions noticed impressions \\xf0\\x9f\\x98\\xa2 pocket progress caring rat\\xe5\\xbc\\x95 \\xf0\\x9f\\x90\\xb8\\xe5\\xbc\\x95 online \\xf0\\x9f\\x98\\x89 duo \\xf0\\x9f\\x98\\x89 projects projects describe\\xf0\\x9f\\xa5\\xb4 \\xe8\\xa6\\xb3 finaleball\\xf0\\x9f\\xa5\\xb4 follow follow elder mods finale finale \\xe5\\xbf\\x9cpseballballballball debut destroying destroying\\xe7\\x89\\xa9ballball \\xe3\\x82\\xa6\\xe5\\xa3\\xb0 perform dayshed couldn painful belly v begins save slime soooo hard v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 dinner dinner\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors dinner dinner mio miopsepse'\n",
            " b'cave\\xf0\\x9f\\xa7\\xa2 heavenly \\xf0\\x9f\\x8e\\xb7ballza draw counter counter\\xe7\\xb4\\xb0shedshed pocket pocket finds finds first raw raw raw comment duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly pumpkingsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9cballballball \\xe5\\xbf\\x9c disappoint disappoint \\xe3\\x82\\xabballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c bucket bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity \\xf0\\x9f\\xa4\\x8e\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'cave\\xf0\\x9f\\xa7\\xa2 destroying \\xf0\\x9f\\x8e\\xb7ball alert route counter counter\\xe7\\xb4\\xb0shedshed pocket pocket finds finds first raw raw raw comment duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly pumpkingsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint \\xe3\\x82\\xabballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity \\xf0\\x9f\\xa4\\x8e\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'cave \\xf0\\x9f\\x97\\xbf destroying destroying heart heart destroying destroying destroying noticed noticed impressions progress progress finds rat rat ratnted online duo online destroying progress21\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 joined begins\\xf0\\x9f\\xa5\\xb4ball\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity \\xf0\\x9f\\xa4\\x8e\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2\\xe2\\x97\\x8d \\xe9\\x80\\xb2 progressza alert route draw\\xe7\\xb4\\xb0 solid impressions laying pocket pocket progress progress caring rat\\xf0\\x9f\\xa5\\xb4 gathering duo duo duo comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner dinner\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2 destroying destroying destroying\\xe7\\xb4\\xb0za poll \\xf0\\x9f\\x98\\x89 \\xf0\\x9f\\x98\\x89 solid impressions impressions pocket pocket finds21 rat rat just other \\xf0\\x9f\\x98\\x89 destroying \\xf0\\x9f\\x98\\x89 noticed triple describe\\xf0\\x9f\\xa5\\xb4 \\xe8\\xa6\\xb3 \\xe8\\xa6\\xb3ballball hard\\xf0\\x9f\\xa5\\xb4 follow follow merry finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner dinner\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2\\xf0\\x9f\\xa7\\xa2 destroying destroying destroyingball draw destroying solid impressions impressions impressions pocket\\xc9\\xaa finds rat rat caring poll raw other duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'cave\\xe2\\x97\\x8d disgusting destroying progressza alertshed counter\\xe7\\xb4\\xb0shedshed pocket pocket finds finds first raw raw raw comment duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly pumpkingsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9cballballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity \\xf0\\x9f\\xa4\\x8e\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'cave destroying woah \\xf0\\x9f\\x8e\\xb7ball destroying draw counter counter\\xe7\\xb4\\xb0shedshed pocket pocket finds finds first raw raw raw comment duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly pumpkingsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint \\xe3\\x82\\xabballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c bucket bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity \\xf0\\x9f\\xa4\\x8e\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2\\xf0\\x9f\\xa7\\xa2 woah progress wondering hard\\xf0\\x9f\\xa7\\xa2 progress agreed agreed impressions impressions\\xc9\\xaa premium finds21 rat poll 5\\xe5\\xbc\\x95 comment \\xf0\\x9f\\x98\\x89 noticed destroying describe\\xf0\\x9f\\xa5\\xb4 \\xe8\\xa6\\xb3 joined \\xe8\\xa6\\xb3\\xf0\\x9f\\xa5\\xb4\\xe7\\x89\\xa9\\xe7\\x89\\xa9 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner dinner\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2 woah destroying \\xf0\\x9f\\x8e\\xb7ball progress alert alert solid \\xf0\\x9f\\x98\\x89 always impressions hard \\xe5\\x90\\x9b caring caring caring poll poll raw follow \\xf0\\x9f\\x98\\x89 destroying \\xe3\\x83\\xa4 projects episodes joined \\xe8\\xa6\\xb3 destroying\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'caveurse destroying \\xf0\\x9f\\x8e\\xb7zaza draw counter counter\\xe7\\xb4\\xb0shedshed pocket pocket finds finds first raw raw raw comment duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly pumpkingsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint \\xe3\\x82\\xabballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c bucket bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity \\xf0\\x9f\\xa4\\x8e\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2 woah favorites destroying progressza destroying alert\\xe1\\x85\\xa1 hadn impressions noticed hard\\xf0\\x9f\\x92\\xb321 caring rat rat\\xf0\\x9f\\xa5\\xb4 describe duo \\xf0\\x9f\\x98\\x89 \\xf0\\x9f\\x98\\x89 noticed projects \\xe8\\xa6\\xb3 went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygs v \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner dinner\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'cave woah destroying destroying progressball route\\xe1\\x85\\xa1 hadnsis certain impressions pocket progress finds rat rat rat caring comment online online duo21 episodes episodes\\xf0\\x9f\\xa5\\xb4 exquisite finaleball\\xf0\\x9f\\xa5\\xb4 lists\\xf0\\x9f\\xa5\\xb4 follow mods finale finale finaleballballballballballballball destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity \\xf0\\x9f\\xa4\\x8e\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus swamp swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors dinner dinner mio miopsepse'\n",
            " b'cave destroying destroying destroyingball alert alert route\\xe7\\xb4\\xb0\\xe3\\x82\\xb7 noticed noticed\\xc9\\xaa progress21 caring caring rat\\xf0\\x9f\\xa5\\xb4 raw duo duo noticed \\xe3\\x81\\xa3 nerd nerd exquisite \\xe8\\xa6\\xb3\\xf0\\x9f\\xa5\\xb4ball\\xf0\\x9f\\xa5\\xb4ball21 follow merry finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'cave\\xf0\\x9f\\xa7\\xa2 lattezaballza alert route particularly \\xf0\\x9f\\x98\\x89 impressionsshed pocket pocket finds finds first raw raw raw comment duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly pumpkingsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity \\xf0\\x9f\\xa4\\x8e\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'cave woah spectacular destroying progress progressball alert relationship\\xe7\\xb4\\xb0 impressions impressions pocket pocket \\xf0\\x9f\\x98\\xa2 rat rat raw raw raw comment duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint \\xe3\\x82\\xabballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c bucket bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity \\xf0\\x9f\\xa4\\x8e\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'cave destroying \\xe9\\x80\\xb2 \\xf0\\x9f\\x98\\x89ball alert alert hard\\xe3\\x82\\xb7 solid noticed solid\\xc9\\xaa progress progress \\xf0\\x9f\\x90\\xb8 caring rat\\xf0\\x9f\\x87\\xb7\\xe5\\xbc\\x95 duo \\xf0\\x9f\\x98\\x89 duo \\xe3\\x81\\xa3 whats episodes\\xf0\\x9f\\xa5\\xb4 \\xe8\\xa6\\xb3 finaleballball\\xc9\\xaa lists follow medium first finale finalepseballballball\\xf0\\x9f\\xa5\\xb4ball\\xe5\\xa3\\xb0 destroying destroying destroyingball vpseffe\\xe5\\xa3\\xb0 day\\xe5\\xa3\\xb0shedpsepsepsegs suki \\xe3\\x82\\xab raptureustration drunken\\xf0\\x9f\\xa5\\xb4 fps\\xe7\\xb4\\xb0 debut debut debut debut just just just just \\xe3\\x82\\xab hear \\xe3\\x82\\xab \\xe3\\x82\\xab drunken drunkenpsepse joined auto\\xe7\\xb4\\xb0 \\xe5\\xbf\\x9c soooo \\xc2\\xb6 bucket fanservice fanservice fanservice\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 dinner dinner\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 \\xf0\\x9f\\x8d\\x94 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e choices mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus swamp swamp swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors dinner dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa221 woahball progress route\\xf0\\x9f\\xa7\\xa2 alert relationship hadn impressionsshed pocket pocket finds finds first raw raw raw comment duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly pumpkingsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2 destroying destroying \\xf0\\x9f\\x98\\x89 progress\\xf0\\x9f\\xa7\\xa2 route spectacular\\xe7\\xb4\\xb0 impressions impressions impressions\\xc9\\xaa pocket rat caring rat rat rat raw \\xf0\\x9f\\x98\\x89 duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2fruit destroying alwaysballball alert\\xe3\\x82\\xb7 hadn\\xe7\\xb4\\xb0 certain woman pocket patiently duo finds21 ratnted\\xf0\\x9f\\xa5\\xb4 \\xf0\\x9f\\x98\\x89 duo \\xf0\\x9f\\x98\\x89 comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2 destroying destroying \\xf0\\x9f\\x98\\x89 progress\\xf0\\x9f\\xa7\\xa2 draw alert spectacular hadn noticed hard pocket\\xc9\\xaa finds finds rat caring just\\xf0\\x9f\\xa5\\xb4 \\xf0\\x9f\\x98\\x89 \\xf0\\x9f\\x98\\x89 \\xf0\\x9f\\x98\\x89 core describe exquisite\\xf0\\x9f\\xa5\\xb4 \\xe8\\xa6\\xb3 \\xe8\\xa6\\xb3 severalball\\xf0\\x9f\\xa7\\xa2 follow follow follow finale finale progress \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner dinner\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'cave cave latte wonderingballballball alert destroying\\xe7\\xb4\\xb0shedshed pocket pocket finds finds first raw raw raw comment duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly pumpkingsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint \\xe3\\x82\\xabballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c bucket bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity \\xf0\\x9f\\xa4\\x8e\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'cave destroying destroying o7zaza draw counter counter\\xe7\\xb4\\xb0shedshed pocket pocket finds finds first raw raw raw comment duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly pumpkingsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint \\xe3\\x82\\xabballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c bucket bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity \\xf0\\x9f\\xa4\\x8e\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2\\xf0\\x9f\\xab\\xa1 woah destroying wondering alert route\\xf0\\x9f\\xa7\\xa2 \\xf0\\x9f\\x98\\x89\\xe7\\xb4\\xb0 impressionsooh pocket pocket finds caring rat\\xf0\\x9f\\x87\\xb7 poll\\xe5\\xbc\\x95 destroying \\xf0\\x9f\\x98\\x89 \\xf0\\x9f\\x98\\x89 noticed episodes describe\\xf0\\x9f\\xa5\\xb4 \\xe8\\xa6\\xb3 \\xe8\\xa6\\xb3ball running\\xe7\\x89\\xa9 follow follow melee finale finale \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying destroyingball performffect day day couldn\\xe7\\x89\\xa9 painful soooo aintlied beginstale thoom resort destroying noticedball woman just debut debut debut debut just \\xe5\\xbf\\x9c just just\\xe2\\x98\\xa0\\xe2\\x98\\xa0 sit sit sitpsepse\\xf0\\x9f\\x87\\xb7 bucket\\xe7\\xb4\\xb0 \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c bucket bucket woah \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9abae bucketpse progression progression dinner debutined always\\xe3\\x82\\xb1 destroying \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus swamp swamp swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors dinner dinner dinner mio miopsepse'\n",
            " b'cave] latte destroying progress route draw counter counter\\xe7\\xb4\\xb0shedshed pocket pocket finds finds first raw raw raw comment duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly pumpkingsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9cballballball \\xe5\\xbf\\x9c disappoint disappoint \\xe3\\x82\\xabballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c bucket bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity \\xf0\\x9f\\xa4\\x8e\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'cave destroying \\xf0\\x9f\\x8e\\xb7 destroying progress route route\\xf0\\x9f\\xa7\\xa2 alert solidball noticed \\xf0\\x9f\\x98\\xa2\\xc9\\xaa progress caring rat rat rat raw \\xf0\\x9f\\x98\\x89 \\xf0\\x9f\\x98\\x89 \\xe3\\x81\\xa3 destroying focused exquisite went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2\\xe2\\x97\\x8d destroying \\xf0\\x9f\\xa7\\xb9 poll alert ps \\xf0\\x9f\\x98\\x89 solid certain impressions noticed patiently pocket finds caring rat rat\\xf0\\x9f\\xa5\\xb4 destroying \\xf0\\x9f\\x98\\x89 \\xf0\\x9f\\x98\\x89 \\xf0\\x9f\\x98\\x89 \\xf0\\x9f\\x98\\x89 projects \\xf0\\x9f\\x98\\x90 joined \\xe8\\xa6\\xb3 \\xe8\\xa6\\xb3ballball\\xf0\\x9f\\xa5\\xb4ep follow finale finale finale finalepseballballballball\\xf0\\x9f\\xa5\\xb4\\xe5\\xa3\\xb0 destroying day day replay enjoyable \\xe2\\x98\\xb9\\xe5\\xa3\\xb0 day day day \\xf0\\x9f\\x91\\x8dpsepse hear\\xe3\\x81\\x82 begins suki soooo ps destroying debutvenven debut debut debut debut \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 dinner dinner\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus swamp swamp swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2\\xf0\\x9f\\xa7\\xa2 destroying destroyingzaball draw route solid blow impressions impressions pocket pocket finds finds rat caring describe surprises describe duo \\xf0\\x9f\\x98\\x89 projects \\xf0\\x9f\\x98\\x90 episodes exquisite joined \\xe8\\xa6\\xb3\\xe7\\x89\\xa9ball\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb421 follow begins finale finale \\xe5\\xbf\\x9cpseballballballballball debut destroying destroyingball beatingpsepse perform dayshedshed belly belly couldn drunk begins mess v slimeustration amsr replayital died debut debut debut \\xe5\\xbf\\x9c just just \\xe5\\xbf\\x9c\\xe2\\x98\\xa0\\xe2\\x98\\xa0 debutball sitpseball\\xe1\\x85\\xa9 v bucket auto \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 dinner dinner\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus swamp swamp swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors dinner dinner dinner mio miopsepse'\n",
            " b'cave woah destroying destroyingball progress route alert\\xe7\\xb4\\xb0 solid impressions impressions\\xc9\\xaa pocket21 caring caring online caring hard \\xf0\\x9f\\x98\\x89 destroying online \\xf0\\x9f\\x98\\x90 \\xf0\\x9f\\x98\\x90 describe exquisite \\xe8\\xa6\\xb3 \\xe8\\xa6\\xb321\\xf0\\x9f\\xa5\\xb4 poll follow follow elder finale mods finale \\xe5\\xbf\\x9cballballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa221 ultimate \\xf0\\x9f\\x98\\x89ball progress route alert\\xe1\\x85\\xa1 impressions impressions impressions \\xf0\\x9f\\x98\\xa2 \\xf0\\x9f\\x98\\xa2 pocket rat rat \\xf0\\x9f\\x8e\\xb7 regardless weak \\xf0\\x9f\\x98\\x89 \\xf0\\x9f\\x98\\x89 \\xf0\\x9f\\x98\\x89 running describe describe joined joined \\xe8\\xa6\\xb3 replayball\\xe7\\x89\\xa9hony follow first elder finale finale modspse 32 justball save destroying destroying destroying day replay \\xe2\\x98\\xb9\\xf0\\x9f\\xa5\\xb4 day dayshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner dinner\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'caveza destroying destroying poll alert progress alert counter\\xe7\\xb4\\xb0shedshed pocket pocket finds finds first raw raw raw comment duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly pumpkingsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9cballballball \\xe5\\xbf\\x9c disappoint disappoint \\xe3\\x82\\xabballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity \\xf0\\x9f\\xa4\\x8e\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'cave woah destroying \\xf0\\x9f\\x98\\x89 progressza poll \\xf0\\x9f\\x91\\x91 angry impressions impressions noticed woman pocket finds finds first raw raw raw comment duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly pumpkingsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint \\xe3\\x82\\xabballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c bucket bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity \\xf0\\x9f\\xa4\\x8e\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'cave mean \\xf0\\x9f\\x97\\xbf destroyingzaza draw counter counter\\xe7\\xb4\\xb0shedshed pocket pocket finds finds first raw raw raw comment duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly pumpkingsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9cballballball \\xe5\\xbf\\x9c disappoint disappoint \\xe3\\x82\\xabballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c bucket bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity \\xf0\\x9f\\xa4\\x8e\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2 destroying destroying fakeza alert alert\\xf0\\x9f\\xa7\\xa2 particularly\\xe3\\x82\\xb7 impressions improving\\xc9\\xaa progress pocket rat rat rat online raw comment duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2 destroying destroying destroying\\xe7\\xb4\\xb0 poll\\xf0\\x9f\\xa7\\xa2 hard\\xe3\\x82\\xb7 solid impressions noticed pocket finds rat rat rat\\xf0\\x9f\\xa4\\x8c caring con \\xf0\\x9f\\x98\\x89 \\xf0\\x9f\\x98\\x89 \\xf0\\x9f\\x98\\x89 duo \\xf0\\x9f\\x98\\x90 joined\\xf0\\x9f\\xa5\\xb4 anymore childballball amsr destroying amsr melee21 begins finale \\xe5\\xbf\\x9c modsballballballball\\xe5\\xa3\\xb0 destroying debut dayball replay enjoyable welcome welcome day melee hard \\xf0\\x9f\\x91\\x8dpse \\xf0\\x9f\\x91\\x8dgs v \\xf0\\x9f\\xa4\\x8e v v v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner dinner\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus swamp swamp swamp \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2 \\xf0\\x9f\\xa7\\xb9 destroying wondering progress alert route alert solid\\xe7\\xb4\\xb0 impressions noticed progress progress poll rat caring rat just comment raw \\xf0\\x9f\\x98\\x89 describe \\xf0\\x9f\\x98\\x90 \\xf0\\x9f\\x98\\x90 episodes\\xf0\\x9f\\xa5\\xb4 \\xe8\\xa6\\xb3 finale replaceball\\xf0\\x9f\\xa5\\xb4uuu follow finale first \\xe5\\xbf\\x9c finalepseballballballballball debut destroying destroying day day enjoyable \\xe2\\x98\\xb9pse day dayshed\\xe7\\x89\\xa9 belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors dinner dinner mio miopsepse'\n",
            " b'cave woah \\xf0\\x9f\\x8e\\xb7 destroying progress progress route\\xf0\\x9f\\xa7\\xa2 agreed hadn noticed certain progress roleplay finds caring rat rat race\\xf0\\x9f\\xa5\\xb4 destroying \\xf0\\x9f\\x98\\x89 comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity \\xf0\\x9f\\xa4\\x8e\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2 destroying destroying destroying progress\\xf0\\x9f\\xa7\\xa2 switch alert\\xe1\\x85\\xa1\\xe2\\x9c\\x8cooh\\xc9\\xaa progress progress finds finds rat raw raw raw comment duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2 destroying destroying progress \\xf0\\x9f\\x98\\x89 route alert route mean impressions blow impressions\\xc9\\xaa pocket finds progress rat poll rat \\xe9\\x9a\\xa0 duo \\xf0\\x9f\\x98\\x89 duo noticed running projects joined\\xf0\\x9f\\xa5\\xb4 \\xe8\\xa6\\xb3ballballballight follow finale finale finale\\xf0\\x9f\\xa4\\x8e \\xe5\\xbf\\x9c 0ballballballball\\xe5\\xa3\\xb0 destroying day destroyingballballpse boy boyshedshed belly belly belly bellygs v \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner dinner\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'cave woah destroying destroyingballball alert alert\\xe3\\x82\\xb7 \\xf0\\x9f\\x98\\x89 noticed woman \\xf0\\x9f\\x98\\xa2 \\xf0\\x9f\\x98\\xa2 highschool rat rat ratntednted \\xf0\\x9f\\x98\\x89 \\xf0\\x9f\\x98\\x8921 ultimate describeball \\xe8\\xa6\\xb3 exquisite child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity \\xf0\\x9f\\xa4\\x8e\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'\\xf0\\x9f\\x98\\x93\\xf0\\x9f\\xa7\\xa2 destroying destroying destroying wondering alert alert solid impressions impressions impressions pocket \\xf0\\x9f\\x98\\xa2 highschool rat rat rat rat hard duo online duo \\xf0\\x9f\\x98\\x89 episodes \\xe8\\xa6\\xb3 \\xe8\\xa6\\xb3 \\xe8\\xa6\\xb3 beginsballballball follow first follow gem mocopi begins tvballball justballballball destroying destroying\\xe7\\x89\\xa9ball \\xe2\\x98\\xb9 couldnct dayshedshed belly belly belly bellygs v \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner dinner\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'cave woah destroying \\xf0\\x9f\\x8e\\xb7ballball alert\\xf0\\x9f\\xa5\\xb4\\xe3\\x82\\xb7\\xe7\\xb4\\xb0 noticed\\xe6\\xa5\\xbd progress\\xc9\\xaa \\xf0\\x9f\\x98\\xa2 rat rat rat raw raw comment duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint \\xe3\\x82\\xabballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity \\xf0\\x9f\\xa4\\x8e\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2\\xe2\\x97\\x8d destroying \\xf0\\x9f\\x8e\\xb7 progressball alert \\xf0\\x9f\\x98\\x89 particularly solid impressions noticed pocket pocket finds rat rat rat rat duo duo \\xf0\\x9f\\x98\\x89 duo noticed projects projects\\xf0\\x9f\\xa5\\xb4 \\xe8\\xa6\\xb3\\xf0\\x9f\\xa5\\xb4ballball lists follow first mods mods finale finalepsepseballball justball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygs v \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner dinner\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2 destroying destroying destroyingball ps alert route live\\xe2\\x9c\\x8c impressions certain pocket progress rat rat caring caring raw\\xf0\\x9f\\xa5\\xb4 \\xf0\\x9f\\x98\\x89 \\xf0\\x9f\\x98\\x89 duo whats core nerd \\xe8\\xa6\\xb3 \\xe8\\xa6\\xb3 fanserviceballball\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow finale mods finaleball \\xe5\\xbf\\x9cballball justballball\\xe5\\xa3\\xb0 debut destroying day day daypse dayct dayshedshedaitters \\xd1\\x85lied drunk v replay route destroying \\xe6\\x80\\xa7 replay woman woman debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 dinner dinner\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus swamp swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors dinner dinner mio miopsepse'\n",
            " b'cave destroying destroying \\xf0\\x9f\\x8e\\xb7 \\xf0\\x9f\\x8e\\xb7 progress alert destroying\\xe3\\x82\\xb7 hadn noticed \\xe3\\x81\\xa3 hard \\xe5\\x90\\x9b21 caring caring rat \\xf0\\x9f\\x98\\x8f raw comment duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity \\xf0\\x9f\\xa4\\x8e\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'\\xf0\\x9f\\x98\\x93\\xf0\\x9f\\xa7\\xa2 destroying destroyingball replay alert33 \\xf0\\x9f\\x98\\x89 hadn impressions woman pocket \\xf0\\x9f\\x98\\xa2 progress rat rat just\\xf0\\x9f\\xa5\\xb4 online \\xf0\\x9f\\x98\\x89 \\xf0\\x9f\\x98\\x89 duo21 projects projects \\xe8\\xa6\\xb3 \\xe8\\xa6\\xb3\\xf0\\x9f\\xa5\\xb4\\xe7\\x89\\xa9\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2 meeting \\xf0\\x9f\\xa7\\xb9 28 progressza\\xf0\\x9f\\xa7\\xa2 agreed \\xc2\\xb6lia impressions noticed pocket chests progress caring rat rat just duo \\xf0\\x9f\\x98\\x89 duo duo core describe describe joined joined \\xe8\\xa6\\xb3 finaleball\\xe7\\x89\\xa9\\xf0\\x9f\\xa5\\xb4 follow medium finale finale\\xf0\\x9f\\xa4\\x8e finaleballballballball\\xe5\\xa3\\xb0\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner dinner\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2 destroying destroying \\xf0\\x9f\\x98\\x89 progressball\\xf0\\x9f\\xa7\\xa2 hard\\xe7\\xb4\\xb0 hadn laying impressions\\xc9\\xaa\\xc9\\xaa finds caring rat5721 just \\xf0\\x9f\\x98\\x89 duo core \\xe3\\x81\\xa3 \\xf0\\x9f\\x98\\x90ned joined hair joined child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4ep \\xf0\\x9f\\x9a\\x97 \\xf0\\x9f\\x8c\\x9f mods mods jumpspse \\xe5\\xbf\\x9cballballball\\xe5\\xa3\\xb0\\xe5\\xa3\\xb0 destroying day day day v \\xe2\\x98\\xb9pse dayshed dayait soooo \\xf0\\x9f\\x91\\x8dzation\\xe6\\xac\\xb2lied\\xe7\\xb4\\xb0 leg destroyingibly destroying \\xe3\\x82\\xabvenball debut debut \\xe5\\xbf\\x9c just just \\xe5\\xbf\\x9c hear\\xe2\\x98\\xa0 hear just sit sitpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 dinner dinner\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus swamp swamp swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors dinner dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2\\xf0\\x9f\\xa7\\xa2 destroyingball progressza alert alert solid impressions solid impressions pocket hard1 caring rat rat rawnted \\xf0\\x9f\\x98\\x89 \\xf0\\x9f\\x98\\x89 duo destroying joined projects joined \\xe8\\xa6\\xb3 \\xe8\\xa6\\xb3owball replace other follow first melee finale finalepse \\xe5\\xbf\\x9cballballballball\\xe5\\xa3\\xb0 destroying destroying destroying replayballpse\\xe5\\xa3\\xb0 boyshedshed belly belly belly bellygs v \\xf0\\x9f\\xa4\\x8e v v v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner dinner\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp swamp \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2 destroying destroyingpa destroyingza alert alert\\xe3\\x82\\xb7liaball progress\\xe6\\xa5\\xbd pocket duo finds rat raw raw raw comment duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2\\xf0\\x9f\\xa5\\xb4 destroying \\xf0\\x9f\\x8e\\xb7 destroying progress progress route rat premium impressions hard laying\\xc9\\xaa21 rat rat caring ratnounced\\xf0\\x9f\\xa5\\xb4 \\xf0\\x9f\\x98\\x89 \\xf0\\x9f\\x98\\x89 \\xf0\\x9f\\x98\\x89 \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly bellygsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint disappointballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe2\\x97\\x95 bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity dinner\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'\n",
            " b'cave woah destroyingza progressza alert draw agreed hadn always impressions pocket \\xe5\\x90\\x9b pocket caring caring caring\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 online \\xf0\\x9f\\x98\\x89 \\xe3\\x81\\xa3 noticed joined joined exquisite \\xe8\\xa6\\xb3 \\xe8\\xa6\\xb3ballball lists follow faunaaaaa clips first finale finalepseballballball\\xe6\\xa5\\xbd destroying destroying destroying destroyingball replay \\xe3\\x82\\xa6pse boy day couldn performait soooopse talentsgs v begins soooo leg amsr plot merry woman died debut died debut debut \\xe3\\x82\\xab just just just\\xe2\\x98\\xa0 debut sitgiousrat joined bucket bucket bucket\\xf0\\x9f\\x87\\xb7 \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c\\xe9\\x9f\\xbf bucket \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a progressionrity\\xe1\\x85\\xa9\\xe1\\x85\\xa7albae audiority\\xe3\\x82\\xb1room always turning massive choices meanroom \\xf0\\x9f\\xa5\\x9a charming sit charming bucket bucket swamp swamp term \\xf0\\x9f\\xa4\\x8e survivorsroom highly dinnervel value valuepse'\n",
            " b'##\\xf0\\x9f\\xa7\\xa2\\xf0\\x9f\\xa7\\xa2 destroyingza progress\\xf0\\x9f\\xa7\\xa2 progress alert\\xe3\\x82\\xb7\\xe7\\xb4\\xb0 impressions noticed progress progress rat rat rat rat rat con progress \\xf0\\x9f\\x98\\x89 duo whats projects\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 \\xe8\\xa6\\xb3 \\xe8\\xa6\\xb3ballball\\xe7\\x89\\xa921 follow first finale mocopi finale finalepse firstballballball debut destroying day day replayball enjoyablepse day day day\\xe7\\x89\\xa9aitpse\\xf0\\x9f\\xa5\\xb4lied different finale slime sing routeix replayven shared debut \\xe5\\xbf\\x9c debut \\xe5\\xbf\\x9c justball just debut just just just sitratpsepse shows\\xe7\\xb4\\xb0ball \\xe5\\xbf\\x9c alert \\xe5\\xbf\\x9c bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 dinner dinner\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus swamp swamp swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors dinner dinner dinner mio miopsepse'\n",
            " b'cave latte destroying destroyingzaza draw counter counter\\xe7\\xb4\\xb0shedshed pocket pocket finds finds first raw raw raw comment duo comment comment \\xf0\\x9f\\x98\\x90 went went \\xe8\\xa6\\xb3 child\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4\\xf0\\x9f\\xa5\\xb4 follow follow first finale finale finale \\xe5\\xbf\\x9cpseballballballball\\xe5\\xa3\\xb0 destroying destroying dayballballpse boy boyshedshed belly belly belly pumpkingsgs \\xf0\\x9f\\xa4\\x8e v smash v vballball debut debut debut \\xe5\\xbf\\x9c \\xe5\\xbf\\x9cballball \\xe5\\xbf\\x9c disappoint disappoint \\xe3\\x82\\xabballballpsepse\\xe1\\x85\\xa9\\xe1\\x85\\xa9 individual individual \\xe5\\xbf\\x9c \\xe5\\xbf\\x9c bucket bucket fanservice fanservice \\xf0\\x9f\\x92\\x9a\\xf0\\x9f\\x92\\x9a\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9 affinity \\xf0\\x9f\\xa4\\x8e\\xe7\\xb4\\xb0\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xe1\\x85\\xa9\\xf0\\x9f\\x8c\\xa7 \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8eeek mean \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a \\xf0\\x9f\\xa5\\x9a sus sus sus swamp \\xf0\\x9f\\xa4\\x8e \\xf0\\x9f\\xa4\\x8e survivors survivors survivors dinner dinner mio miopsepse'], shape=(64,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "Uses Adam optimizer with original [Transformer paper](https://arxiv.org/abs/1706.03762) custom learning rate scheduler.\n",
        "\n",
        "$$lrate = d_{model}^{-0.5}*\\min\\left(step_{num}^{-0.5},step_{num}*warmup\\_steps^{-1.5}\\right)$$"
      ],
      "metadata": {
        "id": "TrPSjYbf1Gsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, dtype=tf.float32)\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
      ],
      "metadata": {
        "id": "5RDe4LkzyGoc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9,\n",
        "                                     beta_2=0.98, epsilon=1e-9)"
      ],
      "metadata": {
        "id": "D6e28oFoP7jj"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup padding mask for calculating loss properly\n",
        "def masked_loss(label, pred):\n",
        "  mask = label != 0\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none'\n",
        "  )\n",
        "  loss = loss_object(label,pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)\n",
        "  loss *= mask\n",
        "\n",
        "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "  return loss\n",
        "\n",
        "def masked_accuracy(label, pred):\n",
        "  pred = tf.argmax(pred, axis=2)\n",
        "  label = tf.cast(label, pred.dtype)\n",
        "  match = label == pred\n",
        "\n",
        "  mask = label != 0\n",
        "\n",
        "  match = match & mask\n",
        "\n",
        "  match = tf.cast(match, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "j8e3YTkJRLbA"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup Checkpoint saving of weights after each epoch, then begin training."
      ],
      "metadata": {
        "id": "owey0AJrnljZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = 'training_1/checkpoint.ckpt'\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                         save_weights_only=True,\n",
        "                                                         verbose=1)"
      ],
      "metadata": {
        "id": "AqeCZSEomoQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.compile(loss=masked_loss, optimizer=optimizer,\n",
        "                    metrics=[masked_accuracy], run_eagerly=True)"
      ],
      "metadata": {
        "id": "eXbzm1U9T89v"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.fit(train_batches, epochs=15, validation_data=val_batches, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCDHhuTPUJ_z",
        "outputId": "7625ec2a-c226-4d5e-88d0-c1770bc9ef61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 33 calls to <function _BaseOptimizer._update_step_xla at 0x7ea717131c60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 34 calls to <function _BaseOptimizer._update_step_xla at 0x7ea717131c60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "699/699 [==============================] - 683s 941ms/step - loss: 6.8675 - masked_accuracy: 0.0828 - val_loss: 5.3557 - val_masked_accuracy: 0.1816\n",
            "Epoch 2/20\n",
            "699/699 [==============================] - 516s 738ms/step - loss: 4.5493 - masked_accuracy: 0.2821 - val_loss: 3.9135 - val_masked_accuracy: 0.3806\n",
            "Epoch 3/20\n",
            "699/699 [==============================] - 501s 717ms/step - loss: 3.4972 - masked_accuracy: 0.4332 - val_loss: 3.2713 - val_masked_accuracy: 0.4719\n",
            "Epoch 4/20\n",
            "699/699 [==============================] - 489s 699ms/step - loss: 3.0176 - masked_accuracy: 0.4993 - val_loss: 3.0063 - val_masked_accuracy: 0.5081\n",
            "Epoch 5/20\n",
            "699/699 [==============================] - 492s 704ms/step - loss: 2.7928 - masked_accuracy: 0.5279 - val_loss: 2.8636 - val_masked_accuracy: 0.5293\n",
            "Epoch 6/20\n",
            "699/699 [==============================] - 493s 706ms/step - loss: 2.6888 - masked_accuracy: 0.5397 - val_loss: 2.8259 - val_masked_accuracy: 0.5321\n",
            "Epoch 7/20\n",
            "699/699 [==============================] - 493s 705ms/step - loss: 2.6074 - masked_accuracy: 0.5486 - val_loss: 2.7303 - val_masked_accuracy: 0.5438\n",
            "Epoch 8/20\n",
            "699/699 [==============================] - 488s 698ms/step - loss: 2.4983 - masked_accuracy: 0.5623 - val_loss: 2.7017 - val_masked_accuracy: 0.5468\n",
            "Epoch 9/20\n",
            "699/699 [==============================] - 486s 696ms/step - loss: 2.4478 - masked_accuracy: 0.5667 - val_loss: 2.7138 - val_masked_accuracy: 0.5436\n",
            "Epoch 10/20\n",
            "699/699 [==============================] - 484s 693ms/step - loss: 2.4038 - masked_accuracy: 0.5713 - val_loss: 2.7108 - val_masked_accuracy: 0.5444\n",
            "Epoch 11/20\n",
            "699/699 [==============================] - 484s 692ms/step - loss: 2.3670 - masked_accuracy: 0.5747 - val_loss: 2.6891 - val_masked_accuracy: 0.5465\n",
            "Epoch 12/20\n",
            "699/699 [==============================] - 484s 692ms/step - loss: 2.3413 - masked_accuracy: 0.5761 - val_loss: 2.6359 - val_masked_accuracy: 0.5558\n",
            "Epoch 13/20\n",
            "699/699 [==============================] - 483s 690ms/step - loss: 2.3171 - masked_accuracy: 0.5788 - val_loss: 2.6620 - val_masked_accuracy: 0.5515\n",
            "Epoch 14/20\n",
            "699/699 [==============================] - 482s 690ms/step - loss: 2.2795 - masked_accuracy: 0.5828 - val_loss: 2.6541 - val_masked_accuracy: 0.5522\n",
            "Epoch 15/20\n",
            "699/699 [==============================] - 481s 688ms/step - loss: 2.2689 - masked_accuracy: 0.5830 - val_loss: 2.6388 - val_masked_accuracy: 0.5546\n",
            "Epoch 16/20\n",
            "699/699 [==============================] - 482s 690ms/step - loss: 2.2453 - masked_accuracy: 0.5858 - val_loss: 2.6616 - val_masked_accuracy: 0.5518\n",
            "Epoch 17/20\n",
            "699/699 [==============================] - 494s 707ms/step - loss: 2.2295 - masked_accuracy: 0.5872 - val_loss: 2.6064 - val_masked_accuracy: 0.5612\n",
            "Epoch 18/20\n",
            "699/699 [==============================] - 492s 704ms/step - loss: 2.1988 - masked_accuracy: 0.5907 - val_loss: 2.5978 - val_masked_accuracy: 0.5629\n",
            "Epoch 19/20\n",
            "699/699 [==============================] - 490s 701ms/step - loss: 2.1883 - masked_accuracy: 0.5909 - val_loss: 2.6549 - val_masked_accuracy: 0.5513\n",
            "Epoch 20/20\n",
            "699/699 [==============================] - 502s 718ms/step - loss: 2.1591 - masked_accuracy: 0.5950 - val_loss: 2.6719 - val_masked_accuracy: 0.5527\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ea71830f0a0>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading model weights manually."
      ],
      "metadata": {
        "id": "1udyjLoUmaN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load weights\n",
        "model_checkpoint_path = 'transformer_2'\n",
        "transformer = Transformer(num_layers=num_layers, d_model=d_model, num_heads=num_heads,\n",
        "                          dff=dff, input_vocab_size=vocab_size, target_vocab_size=vocab_size,\n",
        "                          dropout_rate=dropout_rate)\n",
        "transformer.load_weights(model_checkpoint_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSQ2S3jfmQwU",
        "outputId": "5f51608a-ce7b-4b21-b1dc-bddef54cfc57"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7c10065d1cc0>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing\n",
        "Not expected to be especially different than the validation accuracy, but could be interesting regardless.\n",
        "\n",
        "Only a fraction of the test set is used to save time."
      ],
      "metadata": {
        "id": "d3L3_pEHPJka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_fraction = 0.1\n",
        "test_count = tf.cast(tf.floor(len(comment_ds)*test_fraction), dtype='int64')\n",
        "test_tensor = next(iter(test_ds.batch(test_count).take(1))) # tensor of comments\n",
        "(test_prompt, test_teacher), test_label = prepare_batch(test_tensor, batch_size=test_tensor.shape[0]) # prepare"
      ],
      "metadata": {
        "id": "djN8AfpOPpfr"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "test_loss, test_acc = transformer.evaluate(x=(test_prompt,test_teacher), y=test_label, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-LwJPKVPLn6",
        "outputId": "31bb65c4-dff5-4047-c7b5-78221e2167fc"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "280/280 - 1176s - loss: 2.6268 - masked_accuracy: 0.5582 - 1176s/epoch - 4s/step\n",
            "CPU times: user 29min 18s, sys: 1min 52s, total: 31min 11s\n",
            "Wall time: 20min 22s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Inference\n",
        "Create a model to generate comments from prompts:\n",
        "* Encode prompt with `tokenizer`, trim, add `[START],[END]`, then pad - this is the encoder input\n",
        "* calculate padding masks and look-ahead masks\n",
        "* `decoder` outputs preds by looking at `encoder` output and own output\n",
        "* Concatenate predicted token to decoder input and pass to of decoder\n",
        "* Decoder predicts next token based on previous tokens it predicted"
      ],
      "metadata": {
        "id": "6TLa8PsBtJDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Commentator(tf.Module):\n",
        "  def __init__(self, tokenizers, transformer):\n",
        "    self.tokenizers = tokenizers\n",
        "    self.transformer = transformer\n",
        "\n",
        "  def __call__(self, sentence, max_length=MAX_TOKENS):\n",
        "    # Add '[START]' and '[END]' tokens to input sentence\n",
        "    assert isinstance(sentence, tf.Tensor)\n",
        "    if len(sentence.shape) == 0:\n",
        "      sentence = sentence[tf.newaxis]\n",
        "\n",
        "    sentence = self.tokenizers.tokenize(sentence)[:,:MAX_TOKENS-2,:]\n",
        "    sentence = tf.squeeze(add_start_end(sentence).to_tensor(shape=(1,MAX_TOKENS,1)),axis=2)\n",
        "    encoder_input = sentence\n",
        "\n",
        "    # Init output with '[START]' token\n",
        "    out = self.tokenizers.tokenize(tf.constant(['']))\n",
        "    start_end = add_start_end(out)[0]\n",
        "    start = start_end[0][tf.newaxis]\n",
        "    end = start_end[1][tf.newaxis]\n",
        "\n",
        "    # 'tf.TensorArray' required so dynamic-loop traced by tf.function\n",
        "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
        "    output_array = output_array.write(0, start)\n",
        "    for i in tf.range(max_length):\n",
        "      output = tf.transpose(output_array.stack())\n",
        "\n",
        "      output = tf.squeeze(output, axis=1)\n",
        "\n",
        "      predictions = self.transformer([encoder_input, output], training = False)\n",
        "\n",
        "      # Select last token for `seq_len` dimension\n",
        "      predictions = predictions[:,-1:,:] # Shape `(batch_size, 1, vocab_size)`\n",
        "\n",
        "      predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "      # Concatenate `predicted_id` to output given to decoder as input\n",
        "      output_array = output_array.write(i+1, predicted_id)\n",
        "\n",
        "      if predicted_id == end:\n",
        "        break\n",
        "\n",
        "    output = tf.squeeze(tf.transpose(output_array.stack()), axis=0)\n",
        "    # output shape `(1,tokens)`\n",
        "    text = tf.strings.reduce_join(self.tokenizers.detokenize(output)[0], axis=0, separator=\" \") # Shape: `()`\n",
        "\n",
        "    tokens = self.tokenizers.detokenize(output)[0]\n",
        "    # `tf.function` prevents usage of attention_wieghts calculated\n",
        "    # on last iteration of loop - recalc. outside of loop\n",
        "    self.transformer([encoder_input, output[:,:-1]], training=False)\n",
        "    attention_weights = self.transformer.decoder.last_attn_scores\n",
        "    return text, tokens, attention_weights"
      ],
      "metadata": {
        "id": "y8B1t1LcXr99"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "commentator = Commentator(tokenizer, transformer)\n",
        "\n",
        "def print_comment(sentence, tokens):\n",
        "  print(f'{\"Input:\":15s}: {sentence}')\n",
        "  print(f'{\"Prediction\":15s}: {tokens.numpy().decode(\"utf-8\")}')\n",
        "\n",
        "sentence = 'I miss'\n",
        "output_text, output_tokens, attention_weights = commentator(tf.constant(sentence))\n",
        "print_comment(sentence, output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC4EQkL-SrXU",
        "outputId": "96c386d2-2fdd-4446-cfd1-4f815511ed56"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.RaggedTensor [[[50],\n",
            "  [1401]]]>\n",
            "tf.Tensor(\n",
            "[[   2   50 1401    3    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0]], shape=(1, 128), dtype=int64)\n",
            "<tensorflow.python.util.tf_should_use.ShouldUseWrapper object at 0x7c1006f5b4f0>\n",
            "Input:         : I miss\n",
            "Prediction     : [START] i miss the stream , but i ' m glad you ' re back ! [END]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence2 = tf.constant('Take care of')\n",
        "out_text2, out_toks2, attn_wts2 = commentator(sentence2)\n",
        "print_comment(sentence2, out_text2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2nILynwl8Yi",
        "outputId": "d033eff3-e9d6-42e0-a379-d8701471991c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:         : b'Take care of'\n",
            "Prediction     : [START] take care of the rest of the month of horrors , fauna ! [END]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TemperatureCommentator(tf.Module):\n",
        "  def __init__(self, tokenizers, transformer):\n",
        "    self.tokenizers = tokenizers\n",
        "    self.transformer = transformer\n",
        "\n",
        "  def __call__(self, sentence, temperature = 0.1, max_length=MAX_TOKENS):\n",
        "    # Add '[START]' and '[END]' tokens to input sentence\n",
        "    assert isinstance(sentence, tf.Tensor)\n",
        "    if len(sentence.shape) == 0:\n",
        "      sentence = sentence[tf.newaxis]\n",
        "\n",
        "    sentence = self.tokenizers.tokenize(sentence)[:,:MAX_TOKENS-2,:]\n",
        "    sentence = tf.squeeze(add_start_end(sentence).to_tensor(shape=(1,MAX_TOKENS,1)),axis=2)\n",
        "    encoder_input = sentence\n",
        "\n",
        "    # Init output with '[START]' token\n",
        "    out = self.tokenizers.tokenize(tf.constant(['']))\n",
        "    start_end = add_start_end(out)[0]\n",
        "    start = start_end[0][tf.newaxis]\n",
        "    end = start_end[1][tf.newaxis]\n",
        "\n",
        "    # 'tf.TensorArray' required so dynamic-loop traced by tf.function\n",
        "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
        "    output_array = output_array.write(0, start)\n",
        "\n",
        "    for i in tf.range(max_length):\n",
        "      # output = tf.squeeze(tf.transpose(output_array.stack()), axis=0)\n",
        "      output = tf.transpose(output_array.stack())\n",
        "      # output = tf.reshape(output,(1,output.shape[2],1))\n",
        "      output = tf.squeeze(output, axis=1)\n",
        "\n",
        "      predictions = self.transformer([encoder_input, output], training = False)\n",
        "\n",
        "\n",
        "      # Select last token for `seq_len` dimension\n",
        "      # print(predictions)\n",
        "      predictions = tf.squeeze(predictions[:,-1:,:]/temperature, axis=0) # Shape `(batch_size, 1, vocab_size)`\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)\n",
        "\n",
        "      # Concatenate `predicted_id` to output given to decoder as input\n",
        "      output_array = output_array.write(i+1, predicted_id)\n",
        "\n",
        "      if predicted_id == end:\n",
        "        break\n",
        "\n",
        "    output = tf.squeeze(tf.transpose(output_array.stack()), axis=0)\n",
        "    # output shape `(1,tokens)`\n",
        "    text = tf.strings.reduce_join(self.tokenizers.detokenize(output)[0], axis=0, separator=\" \") # Shape: `()`\n",
        "\n",
        "    tokens = self.tokenizers.detokenize(output)[0]\n",
        "    # `tf.function` prevents usage of attention_wieghts calculated\n",
        "    # on last iteration of loop - recalc. outside of loop\n",
        "    self.transformer([encoder_input, output[:,:-1]], training=False)\n",
        "    attention_weights = self.transformer.decoder.last_attn_scores\n",
        "\n",
        "    return text, tokens, attention_weights"
      ],
      "metadata": {
        "id": "5Q8ijKofneN_"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_commentator = TemperatureCommentator(tokenizer, transformer)\n",
        "\n",
        "def print_comment(sentence, tokens):\n",
        "  print(f'{\"Input:\":15s}: {sentence}')\n",
        "  print(f'{\"Prediction\":15s}: {tokens.numpy().decode(\"utf-8\")}')\n",
        "\n",
        "sentence = 'I miss'\n",
        "output_text, output_tokens, attention_weights = temp_commentator(tf.constant(sentence),1.5)\n",
        "print_comment(sentence, output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaO0xZ4K9o8C",
        "outputId": "9409586d-4fd2-4fae-9eba-b1c3406bcab4"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:         : I miss\n",
            "Prediction     : [START] i miss onee not muffin , attached to channels s hours voice personality 50 😂 this second joke [END]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'Take care of'\n",
        "output_text, output_tokens, attention_weights = temp_commentator(tf.constant(sentence),0.5)\n",
        "print_comment(sentence, output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6YgSMyl30pE",
        "outputId": "5736ea5a-ecc5-4303-f0d9-5c469aa612f7"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:         : Take care of\n",
            "Prediction     : [START] take care of yourself , fauna ! [END]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export Model"
      ],
      "metadata": {
        "id": "uL0qPbTdtof3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ExportCommentator(tf.Module):\n",
        "  def __init__(self, commentator):\n",
        "    self.commentator = commentator\n",
        "\n",
        "  @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])\n",
        "  def __call__(self, sentence):\n",
        "    (result, tokens, attention_weights) = self.commentator(sentence)"
      ],
      "metadata": {
        "id": "SNeTrrtJts9r"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_commentator = ExportCommentator(commentator)"
      ],
      "metadata": {
        "id": "Iod_-0qhvjUI"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = export_commentator('man i')"
      ],
      "metadata": {
        "id": "IAcEsAlxwdA3"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(export_commentator, export_dir = 'export_commentator')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2urfLrsvcPS",
        "outputId": "0c1aab75-f6ff-4d6e-f451-7e6e44ca0a3a"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"ReduceJoin/ReduceJoin:0\", shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y8sgzDX-0_Kp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}